{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "\n",
    "step1: 先讀取資料，再標準化所有feature values，觀察訓練與測試資料的大小。  \n",
    "step2: 完成myknn_regressor的class：暴力法的演算法是先算出每筆測試資料與各個訓練資料的距離，然後找出距離最近的k個鄰居，再依照不同類型算出Y_train的平均值。  \n",
    "step3: 計算實際值與預測值的RMSE。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('msd_data1.pickle', 'rb') as fh1:\n",
    "    msd_data = pickle.load(fh1)\n",
    "\n",
    "doscaling = 1\n",
    "\n",
    "if (doscaling == 1):\n",
    "    xscaler = preprocessing.StandardScaler().fit(msd_data['X_train'])\n",
    "    #standardize feature values\n",
    "    X_train = xscaler.transform(msd_data['X_train'])\n",
    "    X_test = xscaler.transform(msd_data['X_test'])\n",
    "else:\n",
    "    X_train = msd_data['X_train']\n",
    "    X_test = msd_data['X_test']\n",
    "\n",
    "Y_train = msd_data['Y_train']\n",
    "Y_test = msd_data['Y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 5000\n",
      "test_size: 3000\n"
     ]
    }
   ],
   "source": [
    "# size of data\n",
    "print(f'train_size: {X_train.shape[0]}')\n",
    "print(f'test_size: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  38.51784,   55.38723,   10.31652, ...,    6.66624,  -73.75585,\n",
       "           9.47857],\n",
       "       [  44.7309 ,   46.25776,    8.55636, ...,    4.5564 ,   53.49956,\n",
       "           5.39116],\n",
       "       [  43.08912,   45.70197,   17.18467, ...,  -13.64909,   -7.42137,\n",
       "          -4.97266],\n",
       "       ...,\n",
       "       [  39.81814,   62.12221,    6.60567, ...,   28.27807,  -60.00203,\n",
       "         -11.19226],\n",
       "       [  50.25968,   43.10325,   24.72866, ...,    2.71602,  -44.27226,\n",
       "          -2.54583],\n",
       "       [  41.39744,   -8.88692,  -20.15887, ...,    8.63798, -120.34024,\n",
       "           3.65709]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msd_data['X_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myknn_regressor():\n",
    "    def __init__(self, n_neighbors = 10, mean_type = \"equal_weight\"):\n",
    "        \"\"\"mean_type can be equal_weight or remove_outliers.\n",
    "                              equal_weight use the same weight for all neighbors.\n",
    "                              remove_outliers remove neighbors out in [Q1 - 1.5 IQR, Q3 + 1.5IQR].\"\"\"\n",
    "        ### Add your code here ###  \n",
    "        '''save parameters'''   \n",
    "        self.n_neighbors = n_neighbors \n",
    "        self.mean_type = mean_type\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        ### Add your code here ###\n",
    "        '''save training data'''\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "         \n",
    "\n",
    "    def predict(self, x_test):\n",
    "        \"\"\"use remove_outliers only if k>=10\"\"\"\n",
    "         ### Add your code here ###\n",
    "        if self.n_neighbors < 10:\n",
    "            self.mean_type = \"equal_weight\"\n",
    "        \n",
    "        \n",
    "        self.x_test = x_test\n",
    "        n_train = self.x_train.shape[0]\n",
    "        n_test = self.x_test.shape[0]\n",
    "        y_pred = []\n",
    "        \n",
    "        for i in range(n_test): # for every x_test\n",
    "            dist = []\n",
    "            for j in range(n_train): # for every x_train\n",
    "                # Euclidean distance between x_test's ith row and x_train's jth row\n",
    "                d = np.linalg.norm(self.x_test[i,:] - self.x_train[j,:])\n",
    "                dist.append([d, self.y_train[j]])\n",
    "            \n",
    "            sort_dist = sorted(dist, key = lambda l: l[0]) # sort y_train by distance in ascending order\n",
    "\n",
    "\n",
    "            # k nearest neighbors' y_train\n",
    "            k_neighbors = []\n",
    "            for k in range(self.n_neighbors):\n",
    "                k_neighbors.append(sort_dist[k][1]) \n",
    "\n",
    "            \n",
    "            if self.mean_type == \"equal_weight\":\n",
    "                y_pred.append(np.mean(k_neighbors))\n",
    "            else: # remove_outliers\n",
    "                q1 = np.quantile(k_neighbors,0.25) \n",
    "                q3 = np.quantile(k_neighbors,0.75)\n",
    "                iqr = q3 - q1\n",
    "                \n",
    "                new_neighbors = []\n",
    "                for k in range(len(k_neighbors)):\n",
    "                    y = k_neighbors[k]\n",
    "                    if y >= (q1 - (1.5 * iqr)) and y <= (q3 + (1.5 * iqr)):\n",
    "                        new_neighbors.append(y)\n",
    "\n",
    "                y_pred.append(np.mean(new_neighbors))\n",
    "\n",
    "        return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use myknn_regressor\n",
    "myknn = myknn_regressor(20, \"equal_weight\")\n",
    "myknn.fit(X_train, Y_train)\n",
    "ypred = myknn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.25126451549596\n"
     ]
    }
   ],
   "source": [
    "# count RMSE\n",
    "actual = Y_test\n",
    "predicted = ypred\n",
    "square = np.square(np.subtract(actual, predicted))\n",
    "MSE = square.mean()\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "print(f'RMSE: {RMSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1.2 | first 20 predictions:\n",
      "[1993.35 1993.8  2000.65 1991.5  1992.8  1998.5  1988.1  1991.65 2002.25\n",
      " 2003.   2000.5  1998.65 1995.55 1997.2  1995.05 1997.4  1992.15 2000.45\n",
      " 2003.2  1995.75]\n"
     ]
    }
   ],
   "source": [
    "# print first 20 predictions\n",
    "print(\"Q1.2 | first 20 predictions:\")\n",
    "print(ypred[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use myknn_regressor\n",
    "myknn = myknn_regressor(20, \"remove_outliers\")\n",
    "myknn.fit(X_train, Y_train)\n",
    "ypred = myknn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.212572466080376\n"
     ]
    }
   ],
   "source": [
    "# count RMSE\n",
    "actual = Y_test\n",
    "predicted = ypred\n",
    "square = np.square(np.subtract(actual, predicted))\n",
    "MSE = square.mean()\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "print(f'RMSE: {RMSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1.3 | first 20 predictions:\n",
      "1993.35\n",
      "1993.8\n",
      "2000.65\n",
      "1992.7368421052631\n",
      "1992.8\n",
      "2000.0\n",
      "1988.1\n",
      "1991.65\n",
      "2002.25\n",
      "2003.9473684210527\n",
      "2000.5\n",
      "2000.9444444444443\n",
      "1995.55\n",
      "1997.2\n",
      "1998.611111111111\n",
      "1997.4\n",
      "1992.15\n",
      "2003.8333333333333\n",
      "2003.2\n",
      "1995.75\n"
     ]
    }
   ],
   "source": [
    "# print first 20 predictions\n",
    "print(\"Q1.3 | first 20 predictions:\")\n",
    "for i in ypred[:20]:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "klist = [1 , 2 , 3 , 4 , 5 , 10 , 15 , 20 , 25 , 30 , 35 , 40 , 45 , 50 , 55 , 60 , 80 , 100 , 120 , 140 , 160 , 180 , 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### setting1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list1 = []\n",
    "\n",
    "for k in klist:\n",
    "    knn1 = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn1.fit(X_train, Y_train)\n",
    "    ypred1 = knn1.predict(X_test)\n",
    "    \n",
    "    square1 = np.square(np.subtract(Y_test, ypred1))\n",
    "    mse1 = square1.mean()\n",
    "    rmse1 = np.sqrt(mse1)\n",
    "    rmse_list1.append(rmse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13.911074724837043,\n",
       " 15.532793266720144,\n",
       " 16.940552922892845,\n",
       " 18.002388730387977,\n",
       " 18.343036826000212,\n",
       " 15.021429137513293,\n",
       " 13.296503299740124,\n",
       " 12.806235460378927,\n",
       " 12.530762147610975,\n",
       " 12.397271205121445,\n",
       " 12.46698306193871,\n",
       " 12.258833549730578,\n",
       " 12.234514021134364,\n",
       " 12.29800796877283,\n",
       " 12.29592073277421,\n",
       " 12.308465921199657,\n",
       " 12.539125434681107,\n",
       " 12.77006917235246,\n",
       " 12.875273459879082,\n",
       " 13.00256384974389,\n",
       " 13.039734148619237,\n",
       " 13.12649991429551,\n",
       " 13.190248923605145]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_list1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### setting2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No feature scaling\n",
    "doscaling = 0\n",
    "\n",
    "if (doscaling == 1):\n",
    "    xscaler = preprocessing.StandardScaler().fit(msd_data['X_train'])\n",
    "    #standardize feature values\n",
    "    X_train = xscaler.transform(msd_data['X_train'])\n",
    "    X_test = xscaler.transform(msd_data['X_test'])\n",
    "else:\n",
    "    X_train = msd_data['X_train']\n",
    "    X_test = msd_data['X_test']\n",
    "\n",
    "Y_train = msd_data['Y_train']\n",
    "Y_test = msd_data['Y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list2 = []\n",
    "\n",
    "for k in klist:\n",
    "    knn2 = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn2.fit(X_train, Y_train)\n",
    "    ypred2 = knn2.predict(X_test)\n",
    "    \n",
    "    square2 = np.square(np.subtract(Y_test, ypred2))\n",
    "    mse2 = square2.mean()\n",
    "    rmse2 = np.sqrt(mse2)\n",
    "    rmse_list2.append(rmse2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14.923638966418345,\n",
       " 16.527219971913002,\n",
       " 17.958025132699493,\n",
       " 18.922209173349714,\n",
       " 19.2830149786455,\n",
       " 15.532492824184189,\n",
       " 13.574596372145534,\n",
       " 13.365228517811932,\n",
       " 13.05419472813241,\n",
       " 12.818775292515271,\n",
       " 12.52252636917434,\n",
       " 12.618953997855765,\n",
       " 12.639356523705363,\n",
       " 12.519278466961797,\n",
       " 12.599576712466707,\n",
       " 12.60072749222573,\n",
       " 12.871764965743173,\n",
       " 13.047745654582123,\n",
       " 13.095648132108622,\n",
       " 13.170143000995344,\n",
       " 13.196754651554803,\n",
       " 13.26514229098203,\n",
       " 13.213793298418638]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_list2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### setting3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No feature scaling\n",
    "doscaling = 1\n",
    "\n",
    "if (doscaling == 1):\n",
    "    xscaler = preprocessing.StandardScaler().fit(msd_data['X_train'])\n",
    "    #standardize feature values\n",
    "    X_train = xscaler.transform(msd_data['X_train'])\n",
    "    X_test = xscaler.transform(msd_data['X_test'])\n",
    "else:\n",
    "    X_train = msd_data['X_train']\n",
    "    X_test = msd_data['X_test']\n",
    "\n",
    "Y_train = msd_data['Y_train']\n",
    "Y_test = msd_data['Y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb#X42sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m knn3 \u001b[39m=\u001b[39m myknn_regressor(k, \u001b[39m\"\u001b[39m\u001b[39mremove_outliers\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb#X42sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m knn3\u001b[39m.\u001b[39mfit(X_train, Y_train)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb#X42sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m ypred3 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(knn3\u001b[39m.\u001b[39;49mpredict(X_test))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb#X42sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m square3 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msquare(np\u001b[39m.\u001b[39msubtract(Y_test, ypred3))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb#X42sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m mse3 \u001b[39m=\u001b[39m square3\u001b[39m.\u001b[39mmean()\n",
      "\u001b[1;32m/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb Cell 28\u001b[0m in \u001b[0;36mmyknn_regressor.predict\u001b[0;34m(self, x_test)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb#X42sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     d \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_test[i,:] \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx_train[j,:])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb#X42sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     dist\u001b[39m.\u001b[39mappend([d, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_train[j]])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb#X42sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m sort_dist \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(dist, key \u001b[39m=\u001b[39;49m \u001b[39mlambda\u001b[39;49;00m l: l[\u001b[39m0\u001b[39;49m]) \u001b[39m# sort y_train by distance in ascending order\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb#X42sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# k nearest neighbors' y_train\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/chiawen/Desktop/sldl/sldl_2022fall/hw1/hw1.ipynb#X42sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m k_neighbors \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rmse_list3 = []\n",
    "\n",
    "for k in klist:\n",
    "    knn3 = myknn_regressor(k, \"remove_outliers\")\n",
    "    knn3.fit(X_train, Y_train)\n",
    "    ypred3 = np.array(knn3.predict(X_test))\n",
    "    \n",
    "    square3 = np.square(np.subtract(Y_test, ypred3))\n",
    "    mse3 = square3.mean()\n",
    "    rmse3 = np.sqrt(mse3)\n",
    "    rmse_list3.append(rmse3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# draw the error curve\n",
    "\n",
    "plt.plot(klist, rmse_list1, color='red')\n",
    "plt.title('Setting 1')\n",
    "plt.xlabel('k') # title of x-axis\n",
    "plt.ylabel('RMSE') # tile of y-axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cfa4b7dcd7864583d72e5eda12e513f8c53c522d90114d3c5fb0ab3f428a316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
