{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1\n",
    "\n",
    "step1: 先讀取資料，再標準化所有feature values，觀察訓練與測試資料的大小。  \n",
    "step2: 完成myknn_regressor的class：暴力法的演算法是先算出每筆測試資料與各個訓練資料的距離，然後找出距離最近的k個鄰居，再依照不同類型算出Y_train的平均值。  \n",
    "step3: 計算實際值與預測值的RMSE。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn import preprocessing\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with open('msd_data1.pickle', 'rb') as fh1:\n",
    "    msd_data = pickle.load(fh1)\n",
    "\n",
    "doscaling = 1\n",
    "\n",
    "if (doscaling == 1):\n",
    "    xscaler = preprocessing.StandardScaler().fit(msd_data['X_train'])\n",
    "    #standardize feature values\n",
    "    X_train = xscaler.transform(msd_data['X_train'])\n",
    "    X_test = xscaler.transform(msd_data['X_test'])\n",
    "else:\n",
    "    X_train = msd_data['X_train']\n",
    "    X_test = msd_data['X_test']\n",
    "\n",
    "Y_train = msd_data['Y_train']\n",
    "Y_test = msd_data['Y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size: 5000\n",
      "test_size: 3000\n"
     ]
    }
   ],
   "source": [
    "# size of data\n",
    "print(f'train_size: {X_train.shape[0]}')\n",
    "print(f'test_size: {X_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myknn_regressor():\n",
    "    def __init__(self, n_neighbors = 10, mean_type = \"equal_weight\"):\n",
    "        \"\"\"mean_type can be equal_weight or remove_outliers.\n",
    "                              equal_weight use the same weight for all neighbors.\n",
    "                              remove_outliers remove neighbors out in [Q1 - 1.5 IQR, Q3 + 1.5IQR].\"\"\"\n",
    "        ### Add your code here ###  \n",
    "        '''save parameters'''   \n",
    "        self.n_neighbors = n_neighbors \n",
    "        self.mean_type = mean_type\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        ### Add your code here ###\n",
    "        '''save training data'''\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "         \n",
    "\n",
    "    def predict(self, x_test):\n",
    "        \"\"\"use remove_outliers only if k>=10\"\"\"\n",
    "         ### Add your code here ###\n",
    "        if self.n_neighbors < 10:\n",
    "            self.mean_type = \"equal_weight\"\n",
    "        \n",
    "        \n",
    "        self.x_test = x_test\n",
    "        n_train = self.x_train.shape[0]\n",
    "        n_test = self.x_test.shape[0]\n",
    "        y_pred = []\n",
    "        \n",
    "        for i in range(n_test): # for every x_test\n",
    "            dist = []\n",
    "            for j in range(n_train): # for every x_train\n",
    "                # Euclidean distance between x_test's ith row and x_train's jth row\n",
    "                d = np.linalg.norm(self.x_test[i,:] - self.x_train[j,:])\n",
    "                dist.append([d, self.y_train[j]])\n",
    "            \n",
    "            sort_dist = sorted(dist, key = lambda l: l[0]) # sort y_train by distance in ascending order\n",
    "\n",
    "\n",
    "            # k nearest neighbors' y_train\n",
    "            k_neighbors = []\n",
    "            for k in range(self.n_neighbors):\n",
    "                k_neighbors.append(sort_dist[k][1]) \n",
    "\n",
    "            \n",
    "            if self.mean_type == \"equal_weight\":\n",
    "                y_pred.append(np.mean(k_neighbors))\n",
    "            else: # remove_outliers\n",
    "                q1 = np.quantile(k_neighbors,0.25) \n",
    "                q3 = np.quantile(k_neighbors,0.75)\n",
    "                iqr = q3 - q1\n",
    "                \n",
    "                new_neighbors = []\n",
    "                for k in range(len(k_neighbors)):\n",
    "                    y = k_neighbors[k]\n",
    "                    if y >= (q1 - (1.5 * iqr)) and y <= (q3 + (1.5 * iqr)):\n",
    "                        new_neighbors.append(y)\n",
    "\n",
    "                y_pred.append(np.mean(new_neighbors))\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use myknn_regressor\n",
    "myknn = myknn_regressor(20, \"equal_weight\")\n",
    "myknn.fit(X_train, Y_train)\n",
    "ypred = myknn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.25126451549596\n"
     ]
    }
   ],
   "source": [
    "# count RMSE\n",
    "actual = list(Y_test)\n",
    "predicted = ypred\n",
    "square = np.square(np.subtract(actual, predicted))\n",
    "MSE = square.mean()\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "print(f'RMSE: {RMSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1.2 | first 20 predictions:\n",
      "[1993.35, 1993.8, 2000.65, 1991.5, 1992.8, 1998.5, 1988.1, 1991.65, 2002.25, 2003.0, 2000.5, 1998.65, 1995.55, 1997.2, 1995.05, 1997.4, 1992.15, 2000.45, 2003.2, 1995.75]\n"
     ]
    }
   ],
   "source": [
    "# print first 20 predictions\n",
    "print(\"Q1.2 | first 20 predictions:\")\n",
    "print(ypred[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use myknn_regressor\n",
    "myknn = myknn_regressor(20, \"remove_outliers\")\n",
    "myknn.fit(X_train, Y_train)\n",
    "ypred = myknn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 10.212572466080376\n"
     ]
    }
   ],
   "source": [
    "# count RMSE\n",
    "actual = list(Y_test)\n",
    "predicted = ypred\n",
    "square = np.square(np.subtract(actual, predicted))\n",
    "MSE = square.mean()\n",
    "RMSE = np.sqrt(MSE)\n",
    "\n",
    "print(f'RMSE: {RMSE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1.3 | first 20 predictions:\n",
      "[1993.35, 1993.8, 2000.65, 1992.7368421052631, 1992.8, 2000.0, 1988.1, 1991.65, 2002.25, 2003.9473684210527, 2000.5, 2000.9444444444443, 1995.55, 1997.2, 1998.611111111111, 1997.4, 1992.15, 2003.8333333333333, 2003.2, 1995.75]\n"
     ]
    }
   ],
   "source": [
    "# print first 20 predictions\n",
    "print(\"Q1.3 | first 20 predictions:\")\n",
    "print(ypred[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5cfa4b7dcd7864583d72e5eda12e513f8c53c522d90114d3c5fb0ab3f428a316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
