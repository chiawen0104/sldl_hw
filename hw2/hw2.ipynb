{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 統計學習與深度學習\n",
    "### Homework 2\n",
    "\n",
    "\n",
    "請將IPYNB檔與IPYNB Export之HTML檔上傳至COOL作業區。回答作業時建議使用 \"三明治\" 答題法。也就是說，先說明要做什麼，然後列出程式碼與結果，最後說明這些結果的意義。作業自己做。嚴禁抄襲。不接受紙本繳交，不接受遲交。請以英文或中文作答。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第一題 [Data Preprocessing]\n",
    "\n",
    "(10%) 資料前處理是一個重要的工作，本題將利用UCI的\"Adult\" dataset <https://archive.ics.uci.edu/ml/datasets/Adult>來練習資料前處理。我們使用這個資料集的方式是用來建構預測最後一個收入欄位是'>50K'或'<=50K'。這個資料集已經先切好了Training跟Test。我們將會沿用這個切割。\n",
    "\n",
    "資料前處理包含以下工作:\n",
    "* 生成以下numpy變數: x_train(訓練特徵)、y_train(訓練標籤)、x_test(測試特徵)、y_test(測試標籤)。用一個Dictionary組織將這些變數，其中Key為變數名稱，Value為之前生成的變數內容。\n",
    "* 最後一欄為標籤，將'>50K'與'<=50K'轉成1跟0。其他欄位為特徵。\n",
    "* 把所有含有缺值的Rows刪除。\n",
    "* 所有數值欄位標準化(均數為0，變異數為1)。測試資料特徵需用訓練資料的均數與變異數標準化。\n",
    "* 所有類別欄位(如native-country與workclass)都應使用\"1-of-K\"轉換成0與1的欄位。\n",
    "* 我們只考慮在訓練資料中出現超過(含)10次的特徵值。如果一個特徵值出現不到10次，則刪除這個特徵值所對應的1-of-K欄位。\n",
    "* 你可以使用sklearn中的工具函數進行1-of-K encoding與變數標準化。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前處理完成後，比較你生成的Dictionary與由**adult_m50k.pickle**讀入的資料比較，確定內容相同。\n",
    "\n",
    "讀取**adult_m50k.pickle**的方式如下:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個adult50kp是個Dictionary，裡面有:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['x_train', 'y_train', 'x_test', 'y_test', 'columnname', 'num_col'])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult50kp.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中'x_train', 'y_train', 'x_test', 'y_test'分別是訓練資料特徵、訓練資料標記、測試資料特徵、測試資料標記。'num_col'是連續變數特徵的欄位名稱。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['capital-loss',\n",
       " 'hours-per-week',\n",
       " 'capital-gain',\n",
       " 'educational-num',\n",
       " 'age',\n",
       " 'fnlwgt']"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult50kp['num_col']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'columnname'是所有特徵資料的欄位名稱。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['capital-loss', 'hours-per-week', 'capital-gain',\n",
       "       'educational-num', 'age', 'fnlwgt', 'relationship_Husband',\n",
       "       'relationship_Not-in-family', 'relationship_Other-relative',\n",
       "       'relationship_Own-child', 'relationship_Unmarried',\n",
       "       'relationship_Wife', 'race_Amer-Indian-Eskimo',\n",
       "       'race_Asian-Pac-Islander', 'race_Black', 'race_Other',\n",
       "       'race_White', 'gender_Female', 'gender_Male',\n",
       "       'occupation_Adm-clerical', 'occupation_Craft-repair',\n",
       "       'occupation_Exec-managerial', 'occupation_Farming-fishing',\n",
       "       'occupation_Handlers-cleaners', 'occupation_Machine-op-inspct',\n",
       "       'occupation_Other-service', 'occupation_Priv-house-serv',\n",
       "       'occupation_Prof-specialty', 'occupation_Protective-serv',\n",
       "       'occupation_Sales', 'occupation_Tech-support',\n",
       "       'occupation_Transport-moving', 'education_10th', 'education_11th',\n",
       "       'education_12th', 'education_1st-4th', 'education_5th-6th',\n",
       "       'education_7th-8th', 'education_9th', 'education_Assoc-acdm',\n",
       "       'education_Assoc-voc', 'education_Bachelors',\n",
       "       'education_Doctorate', 'education_HS-grad', 'education_Masters',\n",
       "       'education_Preschool', 'education_Prof-school',\n",
       "       'education_Some-college', 'native-country_Cambodia',\n",
       "       'native-country_Canada', 'native-country_China',\n",
       "       'native-country_Columbia', 'native-country_Cuba',\n",
       "       'native-country_Dominican-Republic', 'native-country_Ecuador',\n",
       "       'native-country_El-Salvador', 'native-country_England',\n",
       "       'native-country_France', 'native-country_Germany',\n",
       "       'native-country_Greece', 'native-country_Guatemala',\n",
       "       'native-country_Haiti', 'native-country_Honduras',\n",
       "       'native-country_Hong', 'native-country_Hungary',\n",
       "       'native-country_India', 'native-country_Iran',\n",
       "       'native-country_Ireland', 'native-country_Italy',\n",
       "       'native-country_Jamaica', 'native-country_Japan',\n",
       "       'native-country_Laos', 'native-country_Mexico',\n",
       "       'native-country_Nicaragua',\n",
       "       'native-country_Outlying-US(Guam-USVI-etc)', 'native-country_Peru',\n",
       "       'native-country_Philippines', 'native-country_Poland',\n",
       "       'native-country_Portugal', 'native-country_Puerto-Rico',\n",
       "       'native-country_Scotland', 'native-country_South',\n",
       "       'native-country_Taiwan', 'native-country_Thailand',\n",
       "       'native-country_Trinadad&Tobago', 'native-country_United-States',\n",
       "       'native-country_Vietnam', 'native-country_Yugoslavia',\n",
       "       'workclass_Federal-gov', 'workclass_Local-gov',\n",
       "       'workclass_Private', 'workclass_Self-emp-inc',\n",
       "       'workclass_Self-emp-not-inc', 'workclass_State-gov',\n",
       "       'workclass_Without-pay', 'marital-status_Divorced',\n",
       "       'marital-status_Married-AF-spouse',\n",
       "       'marital-status_Married-civ-spouse',\n",
       "       'marital-status_Married-spouse-absent',\n",
       "       'marital-status_Never-married', 'marital-status_Separated',\n",
       "       'marital-status_Widowed'], dtype='<U41')"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adult50kp['columnname']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了能方便的比較，你所生成的Dictionary中x_train與x_test的欄位順序應該與adult50kp['columnname']相同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "假設你生成的Dictionary叫adult50k，下面的範例程式比較這個變數與由picke檔案讀入的adult50kp中四個主要變數是否相同:\n",
    "\n",
    "```python\n",
    "elems = ['x_train', 'x_test', 'y_train', 'y_test']\n",
    "\n",
    "for aelem in elems:\n",
    "    cnomatch = np.sum(adult50kp[aelem] != adult50k[aelem])\n",
    "    if cnomatch == 0:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"%d elements no match!\" % cnomatch)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了讓大家更清楚欄位的安排，以下針對位在17與18欄(Index由0開始)的'gender_Female', 'gender_Male'操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gender_Female', 'gender_Male'], dtype='<U41')"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colname = adult50kp['columnname']\n",
    "colname[17:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們取出這兩欄來看看:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = adult50kp['x_train']\n",
    "x_train[:, 17:19]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這兩欄應該只有其中一個是1，另一個是0。因此By Rows加總會是1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[:, 17:19].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/fwz5mknj2mbf6z6qnf5_sbcc0000gn/T/ipykernel_31652/1370018958.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dftrain = pd.read_table('adult.data', sep=', ', header=None)\n",
      "/var/folders/ky/fwz5mknj2mbf6z6qnf5_sbcc0000gn/T/ipykernel_31652/1370018958.py:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  dftest = pd.read_table('adult.test', sep=', ', header=None)\n"
     ]
    }
   ],
   "source": [
    "# import data as dataframe\n",
    "import pandas as pd\n",
    "dftrain = pd.read_table('adult.data', sep=', ', header=None)\n",
    "dftest = pd.read_table('adult.test', sep=', ', header=None)\n",
    "\n",
    "col_list = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship' ,'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'label']\n",
    "dftrain.columns = col_list\n",
    "dftest.columns = col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows containing empty values or '?'\n",
    "import numpy as np\n",
    "dftrain = dftrain.replace('?', np.nan)\n",
    "dftest = dftest.replace('?', np.nan)\n",
    "dftrain.dropna(inplace=True)\n",
    "dftest.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  education-num  \\\n",
       "0       39         State-gov   77516   Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38           Private  215646     HS-grad              9   \n",
       "3       53           Private  234721        11th              7   \n",
       "4       28           Private  338409   Bachelors             13   \n",
       "...    ...               ...     ...         ...            ...   \n",
       "32556   27           Private  257302  Assoc-acdm             12   \n",
       "32557   40           Private  154374     HS-grad              9   \n",
       "32558   58           Private  151910     HS-grad              9   \n",
       "32559   22           Private  201490     HS-grad              9   \n",
       "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
       "\n",
       "           marital-status         occupation   relationship   race     sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "...                   ...                ...            ...    ...     ...   \n",
       "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
       "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
       "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
       "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country  label  \n",
       "0              2174             0              40  United-States  <=50K  \n",
       "1                 0             0              13  United-States  <=50K  \n",
       "2                 0             0              40  United-States  <=50K  \n",
       "3                 0             0              40  United-States  <=50K  \n",
       "4                 0             0              40           Cuba  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32556             0             0              38  United-States  <=50K  \n",
       "32557             0             0              40  United-States   >50K  \n",
       "32558             0             0              40  United-States  <=50K  \n",
       "32559             0             0              20  United-States  <=50K  \n",
       "32560         15024             0              40  United-States   >50K  \n",
       "\n",
       "[30162 rows x 15 columns]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>198693</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>245211</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age     workclass  fnlwgt     education  education-num  \\\n",
       "0       25       Private  226802          11th              7   \n",
       "1       38       Private   89814       HS-grad              9   \n",
       "2       28     Local-gov  336951    Assoc-acdm             12   \n",
       "3       44       Private  160323  Some-college             10   \n",
       "5       34       Private  198693          10th              6   \n",
       "...    ...           ...     ...           ...            ...   \n",
       "16275   33       Private  245211     Bachelors             13   \n",
       "16276   39       Private  215419     Bachelors             13   \n",
       "16278   38       Private  374983     Bachelors             13   \n",
       "16279   44       Private   83891     Bachelors             13   \n",
       "16280   35  Self-emp-inc  182148     Bachelors             13   \n",
       "\n",
       "           marital-status         occupation   relationship  \\\n",
       "0           Never-married  Machine-op-inspct      Own-child   \n",
       "1      Married-civ-spouse    Farming-fishing        Husband   \n",
       "2      Married-civ-spouse    Protective-serv        Husband   \n",
       "3      Married-civ-spouse  Machine-op-inspct        Husband   \n",
       "5           Never-married      Other-service  Not-in-family   \n",
       "...                   ...                ...            ...   \n",
       "16275       Never-married     Prof-specialty      Own-child   \n",
       "16276            Divorced     Prof-specialty  Not-in-family   \n",
       "16278  Married-civ-spouse     Prof-specialty        Husband   \n",
       "16279            Divorced       Adm-clerical      Own-child   \n",
       "16280  Married-civ-spouse    Exec-managerial        Husband   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   Black    Male             0             0              40   \n",
       "1                   White    Male             0             0              50   \n",
       "2                   White    Male             0             0              40   \n",
       "3                   Black    Male          7688             0              40   \n",
       "5                   White    Male             0             0              30   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "16275               White    Male             0             0              40   \n",
       "16276               White  Female             0             0              36   \n",
       "16278               White    Male             0             0              50   \n",
       "16279  Asian-Pac-Islander    Male          5455             0              40   \n",
       "16280               White    Male             0             0              60   \n",
       "\n",
       "      native-country   label  \n",
       "0      United-States  <=50K.  \n",
       "1      United-States  <=50K.  \n",
       "2      United-States   >50K.  \n",
       "3      United-States   >50K.  \n",
       "5      United-States  <=50K.  \n",
       "...              ...     ...  \n",
       "16275  United-States  <=50K.  \n",
       "16276  United-States  <=50K.  \n",
       "16278  United-States  <=50K.  \n",
       "16279  United-States  <=50K.  \n",
       "16280  United-States   >50K.  \n",
       "\n",
       "[15060 rows x 15 columns]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to dummy\n",
    "dftrain_dm = pd.get_dummies(dftrain) \n",
    "dftest_dm = pd.get_dummies(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "occupation_Armed-Forces\n",
      "native-country_Holand-Netherlands\n"
     ]
    }
   ],
   "source": [
    "# drop columns (feature < 10) of training data\n",
    "for col in list(dftrain_dm.columns):\n",
    "    subdf = dftrain_dm[col]\n",
    "    if subdf.sum() < 10:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns\n",
    "dftrain_dm.drop(['occupation_Armed-Forces', 'native-country_Holand-Netherlands'], axis=1, inplace=True)\n",
    "dftest_dm.drop(['occupation_Armed-Forces'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "      <th>label_&lt;=50K</th>\n",
       "      <th>label_&gt;50K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>257302</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>154374</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>151910</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>201490</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>287927</td>\n",
       "      <td>9</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0       39   77516             13          2174             0              40   \n",
       "1       50   83311             13             0             0              13   \n",
       "2       38  215646              9             0             0              40   \n",
       "3       53  234721              7             0             0              40   \n",
       "4       28  338409             13             0             0              40   \n",
       "...    ...     ...            ...           ...           ...             ...   \n",
       "32556   27  257302             12             0             0              38   \n",
       "32557   40  154374              9             0             0              40   \n",
       "32558   58  151910              9             0             0              40   \n",
       "32559   22  201490              9             0             0              20   \n",
       "32560   52  287927              9         15024             0              40   \n",
       "\n",
       "       workclass_Federal-gov  workclass_Local-gov  workclass_Private  \\\n",
       "0                          0                    0                  0   \n",
       "1                          0                    0                  0   \n",
       "2                          0                    0                  1   \n",
       "3                          0                    0                  1   \n",
       "4                          0                    0                  1   \n",
       "...                      ...                  ...                ...   \n",
       "32556                      0                    0                  1   \n",
       "32557                      0                    0                  1   \n",
       "32558                      0                    0                  1   \n",
       "32559                      0                    0                  1   \n",
       "32560                      0                    0                  0   \n",
       "\n",
       "       workclass_Self-emp-inc  ...  native-country_Scotland  \\\n",
       "0                           0  ...                        0   \n",
       "1                           0  ...                        0   \n",
       "2                           0  ...                        0   \n",
       "3                           0  ...                        0   \n",
       "4                           0  ...                        0   \n",
       "...                       ...  ...                      ...   \n",
       "32556                       0  ...                        0   \n",
       "32557                       0  ...                        0   \n",
       "32558                       0  ...                        0   \n",
       "32559                       0  ...                        0   \n",
       "32560                       1  ...                        0   \n",
       "\n",
       "       native-country_South  native-country_Taiwan  native-country_Thailand  \\\n",
       "0                         0                      0                        0   \n",
       "1                         0                      0                        0   \n",
       "2                         0                      0                        0   \n",
       "3                         0                      0                        0   \n",
       "4                         0                      0                        0   \n",
       "...                     ...                    ...                      ...   \n",
       "32556                     0                      0                        0   \n",
       "32557                     0                      0                        0   \n",
       "32558                     0                      0                        0   \n",
       "32559                     0                      0                        0   \n",
       "32560                     0                      0                        0   \n",
       "\n",
       "       native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "0                                   0                             1   \n",
       "1                                   0                             1   \n",
       "2                                   0                             1   \n",
       "3                                   0                             1   \n",
       "4                                   0                             0   \n",
       "...                               ...                           ...   \n",
       "32556                               0                             1   \n",
       "32557                               0                             1   \n",
       "32558                               0                             1   \n",
       "32559                               0                             1   \n",
       "32560                               0                             1   \n",
       "\n",
       "       native-country_Vietnam  native-country_Yugoslavia  label_<=50K  \\\n",
       "0                           0                          0            1   \n",
       "1                           0                          0            1   \n",
       "2                           0                          0            1   \n",
       "3                           0                          0            1   \n",
       "4                           0                          0            1   \n",
       "...                       ...                        ...          ...   \n",
       "32556                       0                          0            1   \n",
       "32557                       0                          0            0   \n",
       "32558                       0                          0            1   \n",
       "32559                       0                          0            1   \n",
       "32560                       0                          0            0   \n",
       "\n",
       "       label_>50K  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "...           ...  \n",
       "32556           0  \n",
       "32557           1  \n",
       "32558           0  \n",
       "32559           0  \n",
       "32560           1  \n",
       "\n",
       "[30162 rows x 104 columns]"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftrain_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>workclass_Federal-gov</th>\n",
       "      <th>workclass_Local-gov</th>\n",
       "      <th>workclass_Private</th>\n",
       "      <th>workclass_Self-emp-inc</th>\n",
       "      <th>...</th>\n",
       "      <th>native-country_Scotland</th>\n",
       "      <th>native-country_South</th>\n",
       "      <th>native-country_Taiwan</th>\n",
       "      <th>native-country_Thailand</th>\n",
       "      <th>native-country_Trinadad&amp;Tobago</th>\n",
       "      <th>native-country_United-States</th>\n",
       "      <th>native-country_Vietnam</th>\n",
       "      <th>native-country_Yugoslavia</th>\n",
       "      <th>label_&lt;=50K.</th>\n",
       "      <th>label_&gt;50K.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>226802</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>89814</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>336951</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>160323</td>\n",
       "      <td>10</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>34</td>\n",
       "      <td>198693</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16275</th>\n",
       "      <td>33</td>\n",
       "      <td>245211</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16276</th>\n",
       "      <td>39</td>\n",
       "      <td>215419</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16278</th>\n",
       "      <td>38</td>\n",
       "      <td>374983</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16279</th>\n",
       "      <td>44</td>\n",
       "      <td>83891</td>\n",
       "      <td>13</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16280</th>\n",
       "      <td>35</td>\n",
       "      <td>182148</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  fnlwgt  education-num  capital-gain  capital-loss  hours-per-week  \\\n",
       "0       25  226802              7             0             0              40   \n",
       "1       38   89814              9             0             0              50   \n",
       "2       28  336951             12             0             0              40   \n",
       "3       44  160323             10          7688             0              40   \n",
       "5       34  198693              6             0             0              30   \n",
       "...    ...     ...            ...           ...           ...             ...   \n",
       "16275   33  245211             13             0             0              40   \n",
       "16276   39  215419             13             0             0              36   \n",
       "16278   38  374983             13             0             0              50   \n",
       "16279   44   83891             13          5455             0              40   \n",
       "16280   35  182148             13             0             0              60   \n",
       "\n",
       "       workclass_Federal-gov  workclass_Local-gov  workclass_Private  \\\n",
       "0                          0                    0                  1   \n",
       "1                          0                    0                  1   \n",
       "2                          0                    1                  0   \n",
       "3                          0                    0                  1   \n",
       "5                          0                    0                  1   \n",
       "...                      ...                  ...                ...   \n",
       "16275                      0                    0                  1   \n",
       "16276                      0                    0                  1   \n",
       "16278                      0                    0                  1   \n",
       "16279                      0                    0                  1   \n",
       "16280                      0                    0                  0   \n",
       "\n",
       "       workclass_Self-emp-inc  ...  native-country_Scotland  \\\n",
       "0                           0  ...                        0   \n",
       "1                           0  ...                        0   \n",
       "2                           0  ...                        0   \n",
       "3                           0  ...                        0   \n",
       "5                           0  ...                        0   \n",
       "...                       ...  ...                      ...   \n",
       "16275                       0  ...                        0   \n",
       "16276                       0  ...                        0   \n",
       "16278                       0  ...                        0   \n",
       "16279                       0  ...                        0   \n",
       "16280                       1  ...                        0   \n",
       "\n",
       "       native-country_South  native-country_Taiwan  native-country_Thailand  \\\n",
       "0                         0                      0                        0   \n",
       "1                         0                      0                        0   \n",
       "2                         0                      0                        0   \n",
       "3                         0                      0                        0   \n",
       "5                         0                      0                        0   \n",
       "...                     ...                    ...                      ...   \n",
       "16275                     0                      0                        0   \n",
       "16276                     0                      0                        0   \n",
       "16278                     0                      0                        0   \n",
       "16279                     0                      0                        0   \n",
       "16280                     0                      0                        0   \n",
       "\n",
       "       native-country_Trinadad&Tobago  native-country_United-States  \\\n",
       "0                                   0                             1   \n",
       "1                                   0                             1   \n",
       "2                                   0                             1   \n",
       "3                                   0                             1   \n",
       "5                                   0                             1   \n",
       "...                               ...                           ...   \n",
       "16275                               0                             1   \n",
       "16276                               0                             1   \n",
       "16278                               0                             1   \n",
       "16279                               0                             1   \n",
       "16280                               0                             1   \n",
       "\n",
       "       native-country_Vietnam  native-country_Yugoslavia  label_<=50K.  \\\n",
       "0                           0                          0             1   \n",
       "1                           0                          0             1   \n",
       "2                           0                          0             0   \n",
       "3                           0                          0             0   \n",
       "5                           0                          0             1   \n",
       "...                       ...                        ...           ...   \n",
       "16275                       0                          0             1   \n",
       "16276                       0                          0             1   \n",
       "16278                       0                          0             1   \n",
       "16279                       0                          0             1   \n",
       "16280                       0                          0             0   \n",
       "\n",
       "       label_>50K.  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                1  \n",
       "5                0  \n",
       "...            ...  \n",
       "16275            0  \n",
       "16276            0  \n",
       "16278            0  \n",
       "16279            0  \n",
       "16280            1  \n",
       "\n",
       "[15060 rows x 104 columns]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftest_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert '<=50k' and '>50k' to 0 and 1\n",
    "train_label_num = []\n",
    "for i in list(dftrain_dm['label_<=50K']):\n",
    "    if i == 1: # <=50k\n",
    "        train_label_num.append(0)\n",
    "    else: # >50k\n",
    "        train_label_num.append(1)\n",
    "\n",
    "\n",
    "test_label_num = []\n",
    "for j in list(dftest_dm['label_<=50K.']):\n",
    "    if j == 1:\n",
    "        test_label_num.append(0)\n",
    "    else:\n",
    "        test_label_num.append(1)\n",
    "\n",
    "y_train = train_label_num\n",
    "y_test = test_label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_col = ['capital-loss',\n",
    "            'hours-per-week',\n",
    "            'capital-gain',\n",
    "            'educational-num',\n",
    "            'age',\n",
    "            'fnlwgt']\n",
    "\n",
    "columnname = list(dftrain_dm.columns)\n",
    "columnname = columnname[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain_dm.drop(['label_<=50K', 'label_>50K'], axis=1, inplace=True)\n",
    "dftest_dm.drop(['label_<=50K.', 'label_>50K.'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = dftest_dm.to_numpy()\n",
    "X_train = dftrain_dm.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train[:,:6])\n",
    "X_train_num = scaler.transform(X_train[:,:6])\n",
    "X_test_num = scaler.transform(X_test[:,:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concate array\n",
    "x_train = np.concatenate([X_train_num, X_train[:,6:]], axis=1)\n",
    "x_test = np.concatenate([X_test_num, X_test[:,6:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "adult50k = {'x_train': x_train, 'y_train': np.array(y_train), \n",
    "            'x_test': x_test, 'y_test': np.array(y_test),\n",
    "            'columnname': np.array(columnname), 'num_col': num_col}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train match!\n",
      "x_test match!\n",
      "y_train match!\n",
      "y_test match!\n"
     ]
    }
   ],
   "source": [
    "elems = ['x_train', 'x_test', 'y_train', 'y_test']\n",
    "\n",
    "for aelem in elems:\n",
    "    kpsum = np.sum(adult50kp[aelem]) # sum of adult50kp[aelem]\n",
    "    ksum = np.sum(adult50k[aelem]) # sum of adult50k[aelem]\n",
    "    if kpsum == ksum:\n",
    "        print(aelem, \"match!\")\n",
    "    else:\n",
    "        print(aelem, \"no match!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第二題 [ROC and AUC]\n",
    "(35%) Receiver operation characteristic (ROC)曲線以及其線下面積 (Area Under Curve; AUC)為衡量分類器預測能力常用的工具。本題將練習繪製ROC以及計算AUC。\n",
    "在這之前我們必須載入資料，訓練模型，並進行預測:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.848406\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# load dataset\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "    \n",
    "# train prediction model    \n",
    "c = 0.3\n",
    "lr2 = LogisticRegression(solver = 'lbfgs', C= c, max_iter = 1000)\n",
    "lr2.fit(adult50kp['x_train'], adult50kp['y_train'])\n",
    "# make prediction\n",
    "ypred = lr2.predict(adult50kp['x_test'])\n",
    "ypredprob = lr2.predict_proba(adult50kp['x_test'])\n",
    "# compute accuracy\n",
    "ncorrect = np.sum(adult50kp['y_test'] == ypred)\n",
    "accuracy_sk = ncorrect / adult50kp['y_test'].shape[0]\n",
    "print(\"Accuracy = %f\" % accuracy_sk)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 回答下面問題:\n",
    "\n",
    "* Q2.1 (17.5%): 基於`adult50kp['y_test']`與`ypredprob`繪製ROC Curve。\n",
    "* Q2.2 (17.5%): 計算繪製出的ROC Curve的AUC。\n",
    "\n",
    "規定與提示:\n",
    "* 禁用現成的ROC與AUC計算函數，如 `sklearn.metrics.roc_curve`與`sklearn.metrics.auc`。違者本題零分。\n",
    "* 計算AUC時可以利用相鄰的FP_Rate與其對應的TP_Rate所形成的梯形近似該小塊面積，然後加總所有梯形的面積即可得到AUC。梯形面積計算請參考下圖。\n",
    "\n",
    "![AUC Tip](tipsauc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Steps\n",
    " - 合併ypredprob[:,1]（預測為1的機率）與adult50kp['y_test']\n",
    " - 將上述陣列依機率降序排列\n",
    " - 依序將每一個機率值設為threshold，計算True Positive Rate與False Positive Rate\n",
    " - 繪製ROC曲線"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15060, 2)"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymatrix = np.column_stack([ypredprob[:,1], adult50kp['y_test']])\n",
    "ymatrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00289296, 0.        ],\n",
       "       [0.1224803 , 0.        ],\n",
       "       [0.38135936, 1.        ],\n",
       "       ...,\n",
       "       [0.69729758, 0.        ],\n",
       "       [0.28121256, 0.        ],\n",
       "       [0.79605545, 1.        ]])"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ymatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "ylist = ymatrix.tolist()\n",
    "ylist_sort = sorted(ylist, key=lambda l:l[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_false_positive(threshold, ylist_sort):\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for i in range(ypredprob.shape[0]):\n",
    "        if (ylist_sort[i][0] >= threshold) and (ylist_sort[i][1] == 1.0):\n",
    "            tp += 1\n",
    "        elif (ylist_sort[i][0] < threshold) and (ylist_sort[i][1] == 0.0):\n",
    "            tn += 1\n",
    "        elif (ylist_sort[i][0] >= threshold) and (ylist_sort[i][1] == 0.0):\n",
    "            fp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "    \n",
    "    tpr = tp / (tp + fn)\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    return tpr, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_list = []\n",
    "fpr_list = []\n",
    "\n",
    "for i in range(ypredprob.shape[0]):\n",
    "    tpr, fpr = true_false_positive(ylist_sort[i][0], ylist_sort)\n",
    "    tpr_list.append(tpr)\n",
    "    fpr_list.append(fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAlOklEQVR4nO3debxVdb3/8dfbAzggOAAqgwgWDliOx1nT8jpWP63MIW3Qa15LM2/DzymztLp163rN1LxkZpbDL4fU0tTqRppDCAoIKoYaiEqCYgqCDOfz++O7jmwOZ9gHztrr7L3ez8djP9b03Wt91oHH+uzvd631/SoiMDOz8lqn6ADMzKxYTgRmZiXnRGBmVnJOBGZmJedEYGZWck4EZmYl50RgZlZyTgTWUCT9XdJiSQslzZV0raQN25TZR9L/SnpT0j8l/UbS2DZlBkq6VNLsbF8zs+XBHRxXks6UNE3SIklzJN0s6b15nq9ZT3AisEb04YjYENgZ2AU4t3WDpL2B+4A7gGHAaGAK8KCkrbMy/YA/AjsAhwEDgX2AV4E9OjjmD4EvAmcCmwLbALcDH+xu8JL6dPc7ZmtDfrPYGomkvwOnRMQfsuX/BHaIiA9myw8AT0TE59t873fAvIj4lKRTgG8D74qIhVUccwzwNLB3REzooMx44JcRcXW2/Jkszv2y5QDOAM4C+gD3Agsj4isV+7gD+HNEXCJpGPAj4H3AQuC/I+Kyrv9CZqtzjcAalqQRwOHAzGx5A9Iv+5vbKf4r4OBs/l+Ae6pJApmDgDkdJYFuOArYExgL3AAcK0kAkjYBDgFukrQO8BtSTWZ4dvyzJB26lse3knIisEZ0u6Q3gReAV4ALs/Wbkv7Pv9zOd14GWtv/B3VQpiPdLd+R/4iI1yJiMfAAEMD+2bajgYcj4iVgd2BIRFwUEUsj4jngJ8BxPRCDlZATgTWioyJiAHAgsB0rL/ALgBZgaDvfGQrMz+Zf7aBMR7pbviMvtM5EarO9CTg+W/UJ4PpsfitgmKTXWz/AecDmPRCDlZATgTWsiPgzcC3wg2x5EfAw8PF2ih9DukEM8AfgUEn9qzzUH4ERkpo7KbMI2KBieYv2Qm6zfCNwtKStSE1Gt2brXwCej4iNKz4DIuKIKuM1W4UTgTW6S4GDJe2cLZ8DfDp71HOApE0kfQvYG/hmVuYXpIvtrZK2k7SOpEGSzpO02sU2Iv4GXAncKOlASf0krSfpOEnnZMUmAx+VtIGkdwP/2lXgEfE4MA+4Grg3Il7PNk0A3pB0tqT1JTVJeo+k3bv7xzEDJwJrcBExD7gOuCBb/gtwKPBRUrv+LNIjpvtlF3Qi4m3SDeOngd8Db5AuvoOBv3ZwqDOBy4ErgNeBZ4GPkG7qAvw3sBT4B/BzVjbzdOXGLJYbKs5pBfBh0uOxz5OatK4GNqpyn2ar8OOjZmYl5xqBmVnJORGYmZWcE4GZWck5EZiZlVzddW41ePDgGDVqVNFhmJnVlUmTJs2PiCHtbau7RDBq1CgmTpxYdBhmZnVF0qyOtrlpyMys5JwIzMxKzonAzKzknAjMzErOicDMrORySwSSrpH0iqRpHWyXpMuyQcGnSto1r1jMzKxjedYIriUN/N2Rw4Ex2edU4Mc5xmJmZh3I7T2CiLhf0qhOihwJXJeNxPSIpI0lDY2Inhjyz8zysHw5LF0KK1as/mlpSdPFi2HRolQ+Iv/P3Lmw/vppvvKYazqf1z5mzoTNNlu7v/9++8Ehh6zdPtpR5Atlw6kYmg+Yk61bLRFIOpVUa2DkyJE1Cc6sV4pIF9nXXkufxYth9mx4801YtixdqCs/Tz8Nm266ctuyZenzxBOwxRYry61YsXL++eehXz+Q0vrW7y5cmJZt7Uhr/t2zz264RNDeX6PdwREiYhwwDqC5udkDKFhjWbEiXdznz4cFC+C55+Cll+Bvf4N//CP90p4+Hfr0gRdegDfe6P4xNt0U+vZN++jbNyWUF1+EMWOgqSmtX2+9NN1883T8nXZa9Tt9+qTEs9FGaX9NTat/1lknTd96C4YPTxe9vD8RqUaw3norL7Kt29Z0Po99NDXBBpWjlfYeRSaCOcCWFcsjgJcKisWs5y1eDH/9K7z6amoWeOQRmDMnbVu6FJYsSb/kX+6iNXT0aBg8ONUAjj46LQ8alBLImDHpIjh8OPTvv+pFu/XT1JT/uVpdKzIR3AmcIekm0sDc//T9AasLzz6bLuovvQRTp8KTT8Lbb6cmlKVL0+eldn7TtP7yHjwYmpth3XXTr9jNNkvNNE1N6QK/+eYwciSMGAEbblj787PSyS0RSLoROBAYLGkOcCHQFyAirgLuBo4AZgJvASflFYtZ1ZYuTb/aJ09OF/cpU1JTzCOPpHbyJ55o/3tbbw177JF+jffrlz5vvgm77QYHHJAu6kPa7fjRrHB5PjV0fBfbAzg9r+ObtSsitcP/7W8waVKazpgBr78ODz/c+XcHDYJPfzo1yRxzTGpD32yz9KverI7VXTfUZh1qaUk3V19/PT0tM2sWPP54mi5YkKZvvpnKVVpvvZQgmptTW/tBB8GAAbD33qn5Zqut1u5JD7NezonA6teECekZ8tdfh7vugttvT007bY0dm26wNjfD0KHp4r7JJumZ7O228y96Kz0nAqsPs2fDlVemJ2eefTa14b/22qplhg2Dk09OF/emJth113QTduDAQkI2qxdOBNY7rVgBd98Nf/oT/OY36fHLVu95Dxx4IOy4Y7oRO3Ro+viCb7ZGnAis93jjDXj00ZQALrlk1W0nnAAnnQQf+IDb6816mBOBFef112H8ePjtb+H3v0/NP6223hqOOAK++EV497uLitCsFJwIrLaWLEkX92uvXf3G7k47wamnpuaeHXYoJDyzMnIisPy1tKQner75zfQmbqtDD03P4x9ySHrhyswK4URg+YiAhx6CK66AG29cuX7kSDj3XDjttOJiM7NVOBFYz1q+HC69FH75y9Q9A6Rn+A8+GP7rv9x3jlkv5ERgPeOVV+BLX4Jf/zp1QQzpV/+556ZagJn1Wk4EtnZaWuBnP4OzzkoDlwD84hdw7LGpAzYz6/WcCKz7WlpSh23XXZfe9m1pSS9z/e536Qawn/M3qytOBFa9KVPg3/89ve1b6dhj4cc/Tv33mFndcSKw6nz963DxxSuXzzwTjj8e9tzTNQCzOudEYJ279NJUC4A03up998G++xYakpn1rHWKDsB6oTfeSDd/N954ZRI48MDU5bOTgFnDcY3AVnXPPXD44SuXd9kF7r3XwyyaNTDXCGylCy5YmQR+/OP0NNBjjzkJmDU41wgsdQdx4olwww3Qv38a+Wvs2KKjMrMacY2gzCLgmmugT5+UBA4+GF591UnArGRcIyirCRPgox+FF19Myx//eOocrqmp2LjMrOZcIyibCDjjjPT8/4svpv7/lyyBX/3KScCspFwjKJNp01Lzz9y5afnRR6G5udiYzKxwrhGUQQT84Afw3vemJPC+98HbbzsJmBngGkHjW7gQ9t8fJk+Gfv3Sm8EHHFB0VGbWi7hG0MiuugqGDk1J4PTTYfFiJwEzW41rBI3oqafSE0FPP52Wv/ENuPDCQkMys97LiaDRPPBAugcAsN9+aYwADw9pZp1w01CjWL4cDjlkZRI488yUFJwEzKwLrhE0gvnz4aij4MEH0/Ls2bDlloWGZGb1I9cagaTDJM2QNFPSOe1s30jSbyRNkTRd0kl5xtOQ7roLttoqJYFPfCJ1FOckYGbdkFsikNQEXAEcDowFjpfUthOb04EnI2In4EDgvyT1yyumhnPrrfChD8Fbb8Ett8D113u0MDPrtjybhvYAZkbEcwCSbgKOBJ6sKBPAAEkCNgReA5bnGFPjmDYNjj46zT/7LGy9dbHxmFndyrNpaDjwQsXynGxdpcuB7YGXgCeAL0ZES9sdSTpV0kRJE+fNm5dXvPVjzpz0ljCkF8ScBMxsLeSZCNpro4g2y4cCk4FhwM7A5ZIGrvaliHER0RwRzUPKPkjKSy+tvAfw7W+nvoPMzNZCnolgDlB513IE6Zd/pZOA2yKZCTwPbJdjTPWtsgnokkvgvPOKjcfMGkKeieBRYIyk0dkN4OOAO9uUmQ0cBCBpc2Bb4LkcY6pfb7wBxxyTOov70Y9WDipvZraWcrtZHBHLJZ0B3As0AddExHRJp2XbrwIuBq6V9ASpKensiJifV0x17ZRT0vjBp56axhMwM+shimjbbN+7NTc3x8SJE4sOo7YOOwzuvRe23x6efLLr8mZmbUiaFBHt9j3vLiZ6s5YW+NznUhIAuP/+YuMxs4bkLiZ6q+nT0zgCCxak5fnzYdCgYmMys4bkGkFvNHMm7LxzSgL77APLljkJmFlunAh6mylTYJttUm+if/lL6kOojytuZpYfJ4LeZNKkVAPo0wduvhn23bfoiMysBPxTs7d45pmVg8lPmQI77lhsPGZWGq4R9AaTJsG226b5Sy5xEjCzmnIiKNrVV6+sCdx6q98YNrOacyIo0vXXw2c/m+ZvuSUNOG9mVmO+R1CkE09M0xdfhGHDio3FzEqr6hqBpP55BlIqLS3w5S+n+c98xknAzArVZSKQtI+kJ4GnsuWdJF2Ze2SN7MIL001hgMsvLzYWMyu9amoE/00aQOZVgIiYArwvz6Aa2gMPwLe+leZXrID+rmiZWbGqahqKiBfarFqRQyzlcNxxafrgg7CO79WbWfGquVn8gqR9gMgGmDmTrJnIuuknP0lDTW68cXqD2MysF6jmJ+lpwOmkgefnkMYW/nyOMTWmp55Kg8pA6lTOzKyXqKZGsG1EnFC5QtK+wIP5hNSgPvzhNL3xRvckama9SjU1gh9Vuc468stfpoHnjzlm5T0CM7NeosMagaS9gX2AIZK+VLFpIGkMYqvWT3+aptdeW2gYZmbt6axpqB+wYVZmQMX6N4Cj8wyqoXzvezB+PHzpS7D++kVHY2a2mg4TQUT8GfizpGsjYlYNY2ocEybAuefCXnvBN75RdDRmZu2q5mbxW5K+D+wArNe6MiI+kFtUjWDBAthzzzR/220wYEDn5c3MClLNzeLrgaeB0cA3gb8Dj+YYU/1raVnZodzXvgZDhxYbj5lZJ6pJBIMi4qfAsoj4c0ScDOyVc1z17YIL4O67YcwYuOiioqMxM+tUNU1Dy7Lpy5I+CLwEjMgvpDo3YwZ85ztpfvp0kIqNx8ysC9Ukgm9J2gj4Mun9gYHAWXkGVddOyN69u+UW6Nu32FjMzKrQZSKIiN9ms/8E3g/vvFlsbf3xj2n84cMPh499rOhozMyq0tkLZU3AMaQ+hu6JiGmSPgScB6wP7FKbEOvIBRek6TXXFBuHmVk3dFYj+CmwJTABuEzSLGBv4JyIuL0GsdWXK66Ahx9OyWCLLYqOxsysap0lgmZgx4hokbQeMB94d0TMrU1odWTJEvjKV9L8+ecXG4uZWTd19vjo0ohoAYiIJcAz3U0Ckg6TNEPSTEnndFDmQEmTJU2X9Ofu7L/XOP74lAwuugjWXbfoaMzMuqWzGsF2kqZm8wLelS0LiIjYsbMdZ/cYrgAOJo1j8KikOyPiyYoyGwNXAodFxGxJm635qRTktdfg/vvTfOs9AjOzOtJZIth+Lfe9BzAzIp4DkHQTcCTwZEWZTwC3RcRsgIh4ZS2PWXsnn5ySQes4xGZmdaazTufWtqO54UDlWMdzgD3blNkG6CtpPKmH0x9GxHVtdyTpVOBUgJEjR65lWD1o2TK44w4YNgzOO6/oaMzM1kieo6e390pttFnuA+wGfBA4FLhA0jarfSliXEQ0R0TzkCFDej7SNfVgNkjb+ef7DWIzq1vVvFm8puaQHj9tNYLUPUXbMvMjYhGwSNL9wE7AMznG1XOuvjpNjzqq0DDMzNZGVTUCSetL2rab+34UGCNptKR+wHHAnW3K3AHsL6mPpA1ITUdPdfM4xVi0CG64AT772dQ0ZGZWp7pMBJI+DEwG7smWd5bU9oK+mohYDpwB3Eu6uP8qIqZLOk3SaVmZp7L9TiW9uHZ1RExbw3OprU9/GiLgaA/WZmb1TRFtm+3bFJAmAR8AxkfELtm6qV09PpqX5ubmmDhxYhGHXuntt2G99WDzzeHll31/wMx6PUmTIqK5vW3VNA0tj4h/9nBM9e3669P0O99xEjCzulfNzeJpkj4BNEkaA5wJPJRvWL3cd78LQ4ak5iEzszpXTY3gC6Txit8GbiB1R31WjjH1btOmwd/+BrvvDk1NRUdjZrbWqqkRbBsR5wPuTW3RInjve9P8d79bbCxmZj2kmhrBJZKelnSxpB1yj6g3+9nP0vTCC1cmBDOzOtdlIoiI9wMHAvOAcZKekPS1vAPrlZ5/Pk2/8IVi4zAz60FVvVAWEXMj4jLgNNI7BV/PM6heaenS9LTQuuvCoEFFR2Nm1mOqeaFse0nfkDQNuJz0xNCI3CPrbb76VfjHP2DcuKIjMTPrUdXcLP4ZcCNwSES07SuoPMaPT9NPfrLQMMzMelqXiSAi9qpFIL3a/PkwdSqceaZfIDOzhtNhIpD0q4g4RtITrNp9dFUjlDWU1uag3XYrNg4zsxx02NeQpKER8bKkrdrb3gMD16yRmvc1FJFeHJPSuMR9+9bu2GZmPWSN+hqKiJez2c9HxKzKD/D5PALtle67LyWDc85xEjCzhlTN46MHt7Pu8J4OpNf65jfT9KSTio3DzCwnnd0j+Bzpl//WkqZWbBoAPJh3YL3CkiXw8MOwzTbw7ncXHY2ZWS46e2roBuB3wH8A51SsfzMiXss1qt7iF79I07POKjQMM7M8dZYIIiL+Lun0thskbVqKZND6tJC7mzazBtZVjeBDwCTS46OVD9AHsHWOcRUvAiZOhJEjYYMNio7GzCw3HSaCiPhQNh1du3B6kZkz0/Tkk4uNw8wsZ9X0NbSvpP7Z/ImSLpE0Mv/QCvY//5OmHpzezBpcNY+P/hh4S9JOwP8FZgG/yDWq3uBXv0pPCu1Q7iEYzKzxVTt4fQBHAj+MiB+SHiFtXFOmwAsvwCmnFB2JmVnuqul99E1J5wKfBPaX1AQ09iu2l1+epu5p1MxKoJoawbGkgetPjoi5wHDg+7lGVbQ77oBRo2DYsKIjMTPLXTVDVc4Frgc2kvQhYElEXJd7ZEV56imYNw9OPLHoSMzMaqKap4aOASYAHweOAf4qqXEfpfnJT9J0//2LjcPMrEaquUdwPrB7RLwCIGkI8AfgljwDK8xdd6XpAQcUG4eZWY1Uc49gndYkkHm1yu/Vn4UL4dlnobk5DVJvZlYC1dQI7pF0L2ncYkg3j+/OL6QC3XcfrFiRBqo3MyuJasYs/qqkjwL7kfobGhcRv849siJMnpymH/xgoWGYmdVSZ+MRjAF+ALwLeAL4SkS8WKvACjFpEowZA/37Fx2JmVnNdNbWfw3wW+BjpB5If9TdnUs6TNIMSTMlndNJud0lrSj8aaQJE2DzzQsNwcys1jprGhoQEdmzlMyQ9Fh3dpy9gXwFaajLOcCjku6MiCfbKfc94N7u7L/HTZsG8+fDrrsWGoaZWa11lgjWk7QLK8chWL9yOSK6Sgx7ADMj4jkASTeR+it6sk25LwC3Art3M/aeddttaepup82sZDpLBC8Dl1Qsz61YDuADXex7OPBCxfIcYM/KApKGAx/J9tVhIpB0KnAqwMiROfWAfcMNsPXWsOOO+ezfzKyX6mxgmvev5b7Vzrpos3wpcHZErJDaK/5OLOOAcQDNzc1t97H25s+HGTPg4ouhkzjMzBpRNe8RrKk5wJYVyyOAl9qUaQZuypLAYOAIScsj4vYc41rdjdkrEmPH1vSwZma9QZ6J4FFgjKTRwIvAccAnKgtUDoMp6VrgtzVPAgA335ymfn/AzEoot0QQEcslnUF6GqgJuCYipks6Ldt+VV7H7rYHHoBNNnG3EmZWSl0mAqV2mxOArSPiomy84i0iYkJX342Iu2nTHUVHCSAiPlNVxD2ttTbw8Y8Xcngzs6JV03nclcDewPHZ8puk9wMaw9SpafqtbxUbh5lZQappGtozInaV9DhARCyQ1C/nuGrnpptgm21gyJCiIzEzK0Q1NYJl2du/Ae+MR9CSa1S1NHMmDBxYdBRmZoWpJhFcBvwa2EzSt4G/AN/JNapaef75NPVjo2ZWYtV0Q329pEnAQaSXxI6KiKdyj6wWzj03Tb/4xWLjMDMrUDVPDY0E3gJ+U7kuImbnGVhNvPZamrqjOTMrsWpuFt9Fuj8gYD1gNDAD2CHHuGrjxRdhxIiiozAzK1Q1TUPvrVyWtCvwb7lFVCvLlsGsWbD//kVHYmZWqG4PQp91P11sl9E9Ye5cWLQIDjyw6EjMzApVzT2CL1UsrgPsCszLLaJamTUrTUeP7rycmVmDq+YewYCK+eWkewa35hNODY0fn6ZDhxYahplZ0TpNBNmLZBtGxFdrFE/t3HNPmu67b7FxmJkVrMN7BJL6RMQKUlNQ43n6adhqK1in27dJzMwaSmc1ggmkJDBZ0p3AzcCi1o0RcVvOseXr1VfhPe8pOgozs8JVc49gU+BV0rjCre8TBFC/iaAl6yrJN4rNzDpNBJtlTwxNY2UCaNXz4wbX0oRsKIV3vavYOMzMeoHOEkETsCHVDUJfX6ZPT9O99io2DjOzXqCzRPByRFxUs0hq6R//SFP3Ompm1umbxe3VBBrD4sVp6sFozMw6TQQH1SyKWps1C4YNg759i47EzKxwHSaCiHitloHU1IQJrg2YmWXK+TbVggWwfHnRUZiZ9QrlTASvvAKjRhUdhZlZr1C+RPD222k6cmSxcZiZ9RLlSwRvvJGm229fbBxmZr1E+RLB/Plp6nsEZmZAGRPBkiVp6n6GzMyAMiaCqVPTtH//YuMwM+slypcIbrklTffcs9g4zMx6ifIlgn79oKkJBg4sOhIzs14h10Qg6TBJMyTNlHROO9tPkDQ1+zwkaac84wHgscdgl11yP4yZWb3ILRFk4x1fARwOjAWOl9S2u8/ngQMiYkfgYmBcXvG8o6UF+lQzHo+ZWTnkWSPYA5gZEc9FxFLgJuDIygIR8VBELMgWHwFG5BgPLFwIs2fDfvvlehgzs3qSZyIYDrxQsTwnW9eRfwV+194GSadKmihp4rx589Y8orlz09RvFZuZvSPPRFD1yGaS3k9KBGe3tz0ixkVEc0Q0D1mbXkNffDFNt9lmzfdhZtZg8mwsnwNsWbE8AnipbSFJOwJXA4dHxKs5xpPGIQAYPDjXw5iZ1ZM8awSPAmMkjZbUDzgOuLOygKSRwG3AJyPimRxjSRYuTNONN879UGZm9SK3GkFELJd0BnAv0ARcExHTJZ2Wbb8K+DowCLhSEsDyiGjOK6Z3Bq3fYovcDmFmVm9yfY4yIu4G7m6z7qqK+VOAU/KMYRWvZi1P7l7CzOwd5XqzeNkyWKdcp2xm1pVyXRVbWmCHHYqOwsysVylXInjySdhgg6KjMDPrVcqVCAYMWHmfwMzMgLIlgqVL3TRkZtZGuRLBW2/B+usXHYWZWa9SrkQwd65fJjMza6M8iSACFi2CtemryMysAZUnEbz9dpq6acjMbBXlSQQLFnRdxsyshMqTCN56K00HDCg2DjOzXqY8iWDZsjQdNKjYOMzMepnyJILly9PU4xWbma2iPImgtWmob99i4zAz62XKlwiWLCk2DjOzXqY8iaCpKU09TKWZ2SrKkwgi0jSNhGZmZpnyJQIPTGNmtoryXBVbWtLUNQIzs1WUJxG4acjMrF3lSwRuGjIzW0V5ropuGjIza1d5EoGbhszM2lWeRNBaI3DTkJnZKspzVXSNwMysXeVLBK4RmJmtojxXRd8sNjNrV3kSgZuGzMzaVb5E4KYhM7NVlOeq6KYhM7N2lScRuGnIzKxduSYCSYdJmiFppqRz2tkuSZdl26dK2jW3YNw0ZGbWrtyuipKagCuAw4GxwPGSxrYpdjgwJvucCvw4r3jcNGRm1r48fx7vAcyMiOciYilwE3BkmzJHAtdF8giwsaShuUTjGoGZWbvyvCoOB16oWJ6TretuGSSdKmmipInz5s1bw2iGw9FHw8CBa/Z9M7MG1SfHfbfXBhNrUIaIGAeMA2hubl5te1X22Sd9zMxsFXnWCOYAW1YsjwBeWoMyZmaWozwTwaPAGEmjJfUDjgPubFPmTuBT2dNDewH/jIiXc4zJzMzayK1pKCKWSzoDuBdoAq6JiOmSTsu2XwXcDRwBzATeAk7KKx4zM2tfnvcIiIi7SRf7ynVXVcwHcHqeMZiZWef8LKWZWck5EZiZlZwTgZlZyTkRmJmVnCLW7P2sokiaB8xaw68PBub3YDj1wOdcDj7nclibc94qIoa0t6HuEsHakDQxIpqLjqOWfM7l4HMuh7zO2U1DZmYl50RgZlZyZUsE44oOoAA+53LwOZdDLudcqnsEZma2urLVCMzMrA0nAjOzkmvIRCDpMEkzJM2UdE472yXpsmz7VEm7FhFnT6rinE/IznWqpIck7VREnD2pq3OuKLe7pBWSjq5lfHmo5pwlHShpsqTpkv5c6xh7WhX/tzeS9BtJU7JzrutejCVdI+kVSdM62N7z16+IaKgPqcvrZ4GtgX7AFGBsmzJHAL8jjZC2F/DXouOuwTnvA2ySzR9ehnOuKPe/pF5wjy467hr8O28MPAmMzJY3KzruGpzzecD3svkhwGtAv6JjX4tzfh+wKzCtg+09fv1qxBrBHsDMiHguIpYCNwFHtilzJHBdJI8AG0saWutAe1CX5xwRD0XEgmzxEdJocPWsmn9ngC8AtwKv1DK4nFRzzp8AbouI2QARUe/nXc05BzBAkoANSYlgeW3D7DkRcT/pHDrS49evRkwEw4EXKpbnZOu6W6aedPd8/pX0i6KedXnOkoYDHwGuojFU8++8DbCJpPGSJkn6VM2iy0c153w5sD1pmNsngC9GREttwitEj1+/ch2YpiBqZ13bZ2SrKVNPqj4fSe8nJYL9co0of9Wc86XA2RGxIv1YrHvVnHMfYDfgIGB94GFJj0TEM3kHl5NqzvlQYDLwAeBdwO8lPRARb+QcW1F6/PrViIlgDrBlxfII0i+F7papJ1Wdj6QdgauBwyPi1RrFlpdqzrkZuClLAoOBIyQtj4jbaxJhz6v2//b8iFgELJJ0P7ATUK+JoJpzPgn4bqQG9JmSnge2AybUJsSa6/HrVyM2DT0KjJE0WlI/4DjgzjZl7gQ+ld193wv4Z0S8XOtAe1CX5yxpJHAb8Mk6/nVYqctzjojRETEqIkYBtwCfr+MkANX9374D2F9SH0kbAHsCT9U4zp5UzTnPJtWAkLQ5sC3wXE2jrK0ev341XI0gIpZLOgO4l/TEwTURMV3Sadn2q0hPkBwBzATeIv2iqFtVnvPXgUHAldkv5OVRxz03VnnODaWac46IpyTdA0wFWoCrI6LdxxDrQZX/zhcD10p6gtRscnZE1G331JJuBA4EBkuaA1wI9IX8rl/uYsLMrOQasWnIzMy6wYnAzKzknAjMzErOicDMrOScCMzMSs6JwHqlrLfQyRWfUZ2UXdgDx7tW0vPZsR6TtPca7ONqSWOz+fPabHtobWPM9tP6d5mW9bi5cRfld5Z0RE8c2xqXHx+1XknSwojYsKfLdrKPa4HfRsQtkg4BfhARO67F/tY6pq72K+nnwDMR8e1Oyn8GaI6IM3o6FmscrhFYXZC0oaQ/Zr/Wn5C0Wk+jkoZKur/iF/P+2fpDJD2cffdmSV1doO8H3p1990vZvqZJOitb11/SXVn/99MkHZutHy+pWdJ3gfWzOK7Pti3Mpv+v8hd6VhP5mKQmSd+X9KhSH/P/VsWf5WGyzsYk7aE0zsTj2XTb7E3ci4Bjs1iOzWK/JjvO4+39Ha2Eiu572x9/2vsAK0gdiU0Gfk16C35gtm0w6a3K1hrtwmz6ZeD8bL4JGJCVvR/on60/G/h6O8e7lmy8AuDjwF9Jnbc9AfQndW88HdgF+Bjwk4rvbpRNx5N+fb8TU0WZ1hg/Avw8m+9H6kVyfeBU4GvZ+nWBicDoduJcWHF+NwOHZcsDgT7Z/L8At2bznwEur/j+d4ATs/mNSX0Q9S/639ufYj8N18WENYzFEbFz64KkvsB3JL2P1HXCcGBzYG7Fdx4FrsnK3h4RkyUdAIwFHsy61uhH+iXdnu9L+howj9RD60HAryN14Iak24D9gXuAH0j6Hqk56YFunNfvgMskrQscBtwfEYuz5qgdtXIUtY2AMcDzbb6/vqTJwChgEvD7ivI/lzSG1BNl3w6OfwjwfyR9JVteDxhJffdHZGvJicDqxQmk0ad2i4hlkv5Ouoi9IyLuzxLFB4FfSPo+sAD4fUQcX8UxvhoRt7QuSPqX9gpFxDOSdiP19/Ifku6LiIuqOYmIWCJpPKnr5GOBG1sPB3whIu7tYheLI2JnSRsBvwVOBy4j9bfzp4j4SHZjfXwH3xfwsYiYUU28Vg6+R2D1YiPglSwJvB/Yqm0BSVtlZX4C/JQ03N8jwL6SWtv8N5C0TZXHvB84KvtOf1KzzgOShgFvRcQvgR9kx2lrWVYzac9NpI7C9id1pkY2/VzrdyRtkx2zXRHxT+BM4CvZdzYCXsw2f6ai6JukJrJW9wJfUFY9krRLR8ew8nAisHpxPdAsaSKpdvB0O2UOBCZLepzUjv/DiJhHujDeKGkqKTFsV80BI+Ix0r2DCaR7BldHxOPAe4EJWRPN+cC32vn6OGBq683iNu4jjUv7h0jDL0IaJ+JJ4DGlQcv/hy5q7FksU0hdM/8nqXbyIOn+Qas/AWNbbxaTag59s9imZctWcn581Mys5FwjMDMrOScCM7OScyIwMys5JwIzs5JzIjAzKzknAjOzknMiMDMruf8P1BIoxoRCxPoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(fpr_list, tpr_list, color='red')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.9034908284163803\n"
     ]
    }
   ],
   "source": [
    "area = 0\n",
    "\n",
    "for i in range(len(fpr_list)):\n",
    "    if i > 0:\n",
    "        if fpr_list[i] - fpr_list[i-1] >= 0:\n",
    "            area += 0.5 * (tpr_list[i-1] + tpr_list[i]) * (fpr_list[i] - fpr_list[i-1])\n",
    "\n",
    "print(f'AUC: {area}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 第三題 [Logistic Regression with L2 Regularization]\n",
    "\n",
    "(55%) The Logistic regression with L2 regularization minimize the following error function:\n",
    "\n",
    "\n",
    "$\\frac{\\lambda}{2} w^T w - \\sum_{i=1}^n [ t_i \\ln y_i  + (1 - t_i) \\ln (1 - y_i)],$\n",
    "\n",
    "where $y_i = \\frac{1}{1 + exp({-w^T x_i})}$ and $t_i \\in \\{0, 1\\}$ is the label value, $x_i$ is the feature vector, and $w$ is the regression coefficient vector. \n",
    "\n",
    "\n",
    "We are going to consider an extension of this model to allow different levels of regularization for different regression coefficients. Consider the constant term versus other features. The coefficient of the constant term is usually not regularized in logistic regression. It is because the constant term is related to the odds ratio when all features are zero, and regularizing this term will force the probability of the positive class given a zero feature vector to be 0.5, which may or may not be reasonable.  \n",
    "\n",
    "Another consideration is regarding the continuous-valued features and binary-valued features. We typically normalize continuous-valued features to have zero means and unit variances but keep binary-value features untouched. It makes sense to have a single regularization value for the continuous-valued features since all of them have been normalized. Similarly, if we do not have additional information, then all binary-valued features can have the same level of regularization. However, using the same regularization coefficient for the continuous-valued and binary-valued features may not be reasonable. That is, it is often beneficial to have a regularization coefficient for the continuous-valued features and another regularization coefficient for the binary-valued features. \n",
    "\n",
    "The above discussion suggests that a more sophisticated way to regularize a logistic regression is to have three regularization coefficients: 0 for the constant, $a_1$ for continuous-valued features, and $a_2$ for the binary-valued features. It is possible to further refine the regularization coefficients. However, hyper-parameter tuning associated with more regularization coefficients may be costly. \n",
    "\n",
    "To achieve this goal, we are going to consider a variation of L2-regularized logistic regression that allows different levels of regularization for each coefficient. In the following discussion, we are going to use $X$ to denote the feature matrix in the training data. The i-th row in $X$, $x_i$, is the feature vector for the i-th training data. The last column of $X$ is one unless we do not include the constant term. \n",
    "\n",
    "In this model, each regression coefficient may be associated with a different regularization coefficient. Bearing with the risk of ambigulity, we (again) use the scalar $\\lambda_k$ to denote the regularization coefficient for $w_k$.  The vector $w = [w_1, w_2, ..., w_D]^T$ is the  regression coefficient vector. Let $\\Lambda$ denote the diagonal matrix that have $\\lambda_k$ at $\\Lambda_{kk}$. Our new error function becomes: \n",
    "\n",
    "$E(w) = \\frac{1}{2} w^T \\Lambda w - \\sum_{i=1}^n [ t_i \\ln y_i  + (1 - t_i) \\ln (1 - y_i)],$\n",
    "\n",
    "where $y_i = \\frac{1}{1 + exp({-w^T x_i})}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model allows $w_k$ to have regularization coefficient $\\lambda_k$. If the constant term is the last element in $w$, then setting $\\lambda_D$ to $0$ allows us to free the constant term from regularization. We can set $\\lambda_k$ associated with continuous-valued features to one value, and elements associated with binary-value features to another value. This will achieve our goal of a more refined regularization structure. \n",
    "\n",
    "Following the PRML textbook and the class discussion, we are going to train the model using the Newton-Raphson optimization method. In order to do so, you need to derive the gradient and hessian of $E(w)$. Given the training dataset, we can optimize $w$ via \n",
    "\n",
    "$w^{(new)} = w^{(old)} - H^{-1} \\nabla E$\n",
    "\n",
    "To do so, we need to have an initial vector of $w$ to kick start the iteration. One way to do this is to use the closed-form solution of ridge regression: $w = (X^T X + b I)^{-1} X^T t$, where $t$ is the vector of training labels. Set $b$ to the average of $\\lambda_i$. Another way is to change the original L2 regularization term in ridge regression to $\\frac{1}{2}w^T \\Lambda w$ and derive the new closed-form solution that matches our model. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Python class named mylogistic_l2 that performs model training and prediction. \n",
    "\n",
    "The sample usage should be like the following:\n",
    "```python\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(X_train, Y_train)\n",
    "ypred = logic1.predict(X_test)\n",
    "```\n",
    "The first line is to create an object with the specified regularization coefficient vector, lambda_vec, and set the maximum number of iteration to 1000. The \"tol\" parameter sets the stopping condition for Newton-Raphson optimization. The iteration will stop if the improvement on the error function is less than $10^{-5}$. The \"add_intercept\" option says that we need to add a column of ones to the end of X_train before model training. The length of lambda_vec, as a result, should match the number of columns after adding the \"one column\" when this option is turned on. \n",
    "\n",
    "Use the following skeleton to create your mylogistic_l2 class:\n",
    "```python\n",
    "class mylogistic_l2():\n",
    "    def __init__(self, reg_vec, max_iter = 100, tol = 1e-5, add_intercept = True):\n",
    "        \"\"\"reg_vec: the regularization coefficient vector\n",
    "           max_iter: maximum number of iteration to run for the Newton method\n",
    "           tol: tolerance for the objective function\n",
    "           add_intercept: whether to add intercept (a column of ones) at last column of the feature matrix\"\"\"\n",
    "        ### Add your code here\n",
    "\n",
    "    def fit(self, x, y, verbal = False):\n",
    "        # Add your code here\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"doing prediction\"\"\"\n",
    "        ### add your code here.     \n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "To simplify the discussion, we use 0.5 as the threshold for the positive case when making predictions. That is, the output of the last line should be a numpy array of 0 and 1s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementation Restrictions\n",
    "You are allowed to use the \"building block\" libraries including numpy and scipy in your own mylogistic_l2 class. You will receive a zero score if you adopted an existing logistic regression classifier in your answer. The input features and labels for the training method should be numpy arrays. The input features and output labels for the predict method should be numpy arrays. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset\n",
    "We are going to use to \"Adult\" dataset on the UCI machine learning reposition <https://archive.ics.uci.edu/ml/datasets/Adult>. Do not download the raw data from the website. Instead, load the processed data from **adult_m50k.pickle** using the following sample code: \n",
    "\n",
    "```python\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "```    \n",
    "    \n",
    "You can access the training and test data using the following keys: 'x_train', 'x_test', 'y_train', 'y_test'. In addition, the key 'columnname' map the a list of column names, and the key 'num_col' map to a list of numeric columns. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer the following questions:\n",
    "\n",
    "* Q3.1 (15%) Derive the gradient and hessian matrix for the new E(w). \n",
    "* Q3.2 (25%) Create your mylogistic_l2 class. Train your model and show the learned $w$ as well as test accuracy for the cases below. If $w$ is too long for you, show selected $w$ for continuous-valued, binary-valued, and the constant term.  \n",
    "    * Case 1: lambda = 1 for all coefficients\n",
    "    * Case 2: lambda = 1 for all but the intercept, no regularization for intercept term.\n",
    "    * Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term.\n",
    "* Q3.3 (10%) Further split the training data into subtraining (90%) and tuning (10%) to search for the best hyperparameters. Set the regularization coefficient for the constant term to zero. Allow different regularizations for continuous-valued and binary-valued features. Let $a_1$ and $a_2$ denote the regularization coefficients for continuous-valued and binary-valued features. Search the best $a_1$ and $a_2$ and report the test accuracy using the best hyper-parameters. You should follow the following procedure to search for the best hyperparameters. \n",
    "    1. Choose a set of grids among a reasonable range. For example, 10 grids in [0.01, 100]. \n",
    "    2. Conduct grid search with the constraint that $a_1 = a_2$. Record the best value $a_1^*$ and $a_2^*$.\n",
    "    3. Fix $a_1 = a_1^*$, and search $a_2$ for the best value, call the result the new $a_2^*$. \n",
    "    4. Fix $a_2 = a_2^*$, and search $a_1$ for the best value.\n",
    "    5. Report the selected $a_1$ and $a_2$.\n",
    "    6. Train a model using the selected hyper-parameters, and report the test accuracy. \n",
    "  \n",
    "* Q3.4 (5%) Use sklearn.linear_model.LogisticRegression to train and test the model (including hyperparameter tuning). Compare the estimated parameters and test accuracy with those from your own models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$E(w) = \\frac{1}{2} w^T \\Lambda w - \\sum_{i=1}^n [ t_i \\ln y_i  + (1 - t_i) \\ln (1 - y_i)]$\n",
    "\n",
    "Gradient:\n",
    "$\\nabla E(w) = \\sum_{i=1}^{n}((y_i-t_i)\\phi_i) + \\Lambda w$\n",
    "\n",
    "Hessian: \n",
    "$\\nabla \\nabla E(w) = \\sum_{i=1}^{n}(y_i(1-y_i)\\phi_i \\phi_i^T) + \\Lambda$\n",
    "\n",
    "\n",
    "($\\phi_i$ is a feature vector for i-th training data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class mylogistic_l2():\n",
    "    def __init__(self, reg_vec, max_iter = 100, tol = 1e-5, add_intercept = True):\n",
    "        \"\"\"reg_vec: the regularization coefficient vector\n",
    "           max_iter: maximum number of iteration to run for the Newton method\n",
    "           tol: tolerance for the objective function\n",
    "           add_intercept: whether to add intercept (a column of ones) at last column of the feature matrix\"\"\"\n",
    "        ### Add your code here\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "\n",
    "    def fit(self, x, y, verbal = False):\n",
    "        # Add your code here\n",
    "        self.xtrain = x\n",
    "        self.label = np.array([list(y)]).T # t: label\n",
    "        self.verbal = verbal\n",
    "\n",
    "        if self.add_intercept: # add constant column (x[:,-1])\n",
    "            self.xtrain = np.column_stack((x, np.ones(len(x))))\n",
    "\n",
    "        # count initial w\n",
    "        # (X.T * X + bI)^(-1) * X.T * t\n",
    "        # b = avg (reg_vec)\n",
    "        I = np.identity(len(self.reg_vec))\n",
    "        a1 = np.dot(self.xtrain.T, self.xtrain) + np.dot(self.reg_vec.mean(), I)\n",
    "        a2 = np.linalg.inv(a1)\n",
    "        w = np.dot(np.dot(a2, (self.xtrain.T)), self.label)\n",
    "\n",
    "        # build diagonal matrix: Lambda (m * m)\n",
    "        Lam_mtx = np.diag(self.reg_vec)\n",
    "\n",
    "        def sigmoid(z): # return values between 0, 1\n",
    "            return 1.0 / (1 + np.exp(-z))\n",
    "        \n",
    "        def loss (W, Lam, Label, X):\n",
    "            # for i in range(x.shape[0]):\n",
    "            #     # print(np.log(sigmoid(np.dot(X[i,:], W)))[0])\n",
    "            #     yi = count_y(X[i,:], W)\n",
    "            #     summ += np.dot(Label[i], np.log(yi)) + np.dot((1 - Label[i]), np.log(1 - yi))\n",
    "            Y = sigmoid(np.dot(X, W))\n",
    "            summ = np.dot(Label.T, np.log(Y + 1e-5)) + np.dot((1 - Label).T, np.log((1 - Y) + 1e-5))\n",
    "            return ((0.5 * np.dot(np.dot(W.T, Lam), W)) - summ)[0][0]\n",
    "\n",
    "        \n",
    "        def gradient (W, Lam, Label, X):\n",
    "            Y = sigmoid(np.dot(X, W))    \n",
    "            return np.dot(X.T, Y - Label) + np.dot(Lam, W)\n",
    "            \n",
    "            \n",
    "        def hessian (W, Lam, Label, X):\n",
    "            Y = sigmoid(np.dot(X, W))\n",
    "            N = X.shape[0]\n",
    "            R = np.diag((Y - np.square(Y)).reshape(N,)) # R is nxn diagonal matrix\n",
    "            return np.dot(np.dot(X.T, R), X) + Lam\n",
    "\n",
    "        # initial loss E\n",
    "        E = loss(w, Lam_mtx, self.label, self.xtrain)\n",
    "        \n",
    "        # iteration\n",
    "        for iter in range(self.max_iter):\n",
    "            lastE = E\n",
    "            Grad = gradient(w, Lam_mtx, self.label, self.xtrain)\n",
    "            Hess = hessian(w, Lam_mtx, self.label, self.xtrain)\n",
    "            new_w = w - np.dot(np.linalg.inv(Hess), Grad)\n",
    "            E = loss(new_w, Lam_mtx, self.label, self.xtrain) # update loss\n",
    "            w = new_w # update w\n",
    "            # print(f'loss E: {E}')\n",
    "\n",
    "            # check stopping condition\n",
    "            if abs(E - lastE) < self.tol:\n",
    "                break\n",
    "\n",
    "        # print(f'loss: {loss(w, Lam_mtx, self.label, self.xtrain)}')\n",
    "        self.loss = E\n",
    "        self.regre_coef = w\n",
    "\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"doing prediction\"\"\"\n",
    "        ### add your code here.\n",
    "        self.xtest = x\n",
    "\n",
    "        if self.add_intercept:\n",
    "            self.xtest = np.column_stack((x, np.ones(len(x))))\n",
    "\n",
    "        def sigmoid(z): # return values between 0, 1\n",
    "            return 1 / (1 + np.exp(-z))\n",
    "\n",
    "        y_pred = sigmoid(np.dot(self.xtest, self.regre_coef))\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "dsfile = 'adult_m50k.pickle'\n",
    "with open(dsfile, 'rb') as fh1:\n",
    "    adult50kp = pickle.load(fh1)\n",
    "\n",
    "X_train = adult50kp['x_train']\n",
    "Y_train = adult50kp['y_train']\n",
    "X_test = adult50kp['x_test']\n",
    "Y_test = adult50kp['y_test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Case1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [1] * (X_train.shape[1] + 1)\n",
    "lambda_vec1 = np.array(l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 1\n",
    "# train and predict \n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec1, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(X_train, Y_train)\n",
    "ypred1 = logic1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous-valued: \n",
      "[[0.25831075]\n",
      " [0.35295138]\n",
      " [2.33390153]\n",
      " [0.75114521]\n",
      " [0.33352443]\n",
      " [0.07923687]]\n",
      "constant term: \n",
      "[-1.34552489]\n",
      "binary-valued: \n",
      "[[-2.59305996e-01]\n",
      " [-3.31058935e-02]\n",
      " [-8.02092305e-01]\n",
      " [-1.16328381e+00]\n",
      " [-1.57480242e-01]\n",
      " [ 1.06974336e+00]\n",
      " [-6.33846060e-01]\n",
      " [ 1.16732407e-01]\n",
      " [-2.31567383e-01]\n",
      " [-5.17122209e-01]\n",
      " [-7.97216481e-02]\n",
      " [-1.09949780e+00]\n",
      " [-2.46027090e-01]\n",
      " [ 6.19694925e-02]\n",
      " [ 1.26685883e-01]\n",
      " [ 8.62656059e-01]\n",
      " [-9.18352843e-01]\n",
      " [-6.21226177e-01]\n",
      " [-2.00740224e-01]\n",
      " [-7.51600981e-01]\n",
      " [-1.61011588e+00]\n",
      " [ 5.75820911e-01]\n",
      " [ 6.48995282e-01]\n",
      " [ 3.53741433e-01]\n",
      " [ 7.17218474e-01]\n",
      " [-2.84494746e-02]\n",
      " [-9.54820902e-04]\n",
      " [-1.96540899e-01]\n",
      " [-1.46351641e-01]\n",
      " [ 6.26946274e-01]\n",
      " [ 4.48207080e-01]\n",
      " [ 2.45945817e-02]\n",
      " [ 4.69223656e-02]\n",
      " [-4.91067747e-01]\n",
      " [-2.03035424e-01]\n",
      " [-1.63303681e-01]\n",
      " [-1.76623509e-02]\n",
      " [-1.11328323e-01]\n",
      " [-9.94618248e-02]\n",
      " [-1.17391916e+00]\n",
      " [ 1.80702677e-01]\n",
      " [-6.92720011e-02]\n",
      " [ 9.76496905e-01]\n",
      " [ 4.60988601e-01]\n",
      " [-4.95440415e-01]\n",
      " [-1.27203531e+00]\n",
      " [ 4.86772406e-01]\n",
      " [-8.98963733e-01]\n",
      " [-6.00542600e-02]\n",
      " [-3.50848853e-01]\n",
      " [ 4.32815220e-01]\n",
      " [ 5.94120149e-01]\n",
      " [ 5.82151924e-01]\n",
      " [-6.20962284e-01]\n",
      " [-5.97480379e-02]\n",
      " [ 9.29035249e-02]\n",
      " [-1.51892101e-01]\n",
      " [-5.38528876e-03]\n",
      " [ 3.41609085e-02]\n",
      " [-2.89088237e-01]\n",
      " [ 1.56053911e-01]\n",
      " [ 4.95401242e-01]\n",
      " [ 8.90942264e-01]\n",
      " [ 1.49151436e-01]\n",
      " [ 3.42484780e-01]\n",
      " [-3.13312160e-01]\n",
      " [-3.55939108e-01]\n",
      " [-3.62494608e-01]\n",
      " [-6.67247475e-01]\n",
      " [-4.08831131e-01]\n",
      " [ 4.47489831e-01]\n",
      " [ 1.37768930e-01]\n",
      " [ 1.41351233e-01]\n",
      " [-1.16015422e-01]\n",
      " [-5.61032710e-02]\n",
      " [-9.34583043e-01]\n",
      " [-2.92596528e-02]\n",
      " [-2.99012958e-01]\n",
      " [-1.50511251e-01]\n",
      " [ 3.52331870e-01]\n",
      " [-7.85846535e-01]\n",
      " [ 5.80200206e-01]\n",
      " [ 4.97042310e-01]\n",
      " [-1.90320741e-01]\n",
      " [-3.47718541e-04]\n",
      " [ 1.74993803e-01]\n",
      " [-4.88202696e-01]\n",
      " [-3.12259617e-01]\n",
      " [-1.02643023e+00]\n",
      " [-7.22310843e-01]\n",
      " [ 1.44672470e+00]\n",
      " [ 1.15520747e+00]\n",
      " [-6.80202911e-01]\n",
      " [-1.21195631e+00]\n",
      " [-7.98338514e-01]\n",
      " [-5.34648493e-01]]\n"
     ]
    }
   ],
   "source": [
    "# show the learned w\n",
    "print(f'continuous-valued: \\n{logic1.regre_coef[:6]}')\n",
    "print(f'constant term: \\n{logic1.regre_coef[-1]}')\n",
    "print(f'binary-valued: \\n{logic1.regre_coef[6:-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.847875166002656\n"
     ]
    }
   ],
   "source": [
    "# count accuracy\n",
    "tp, tn = 0, 0\n",
    "\n",
    "for i in range(len(ypred1)):\n",
    "    if ypred1[i] >= 0.5 and Y_test[i] == 1:\n",
    "        tp += 1\n",
    "    elif ypred1[i] < 0.5 and Y_test[i] == 0:\n",
    "        tn += 1\n",
    "\n",
    "print(f'accuracy: {(tp + tn) / len(ypred1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Case2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "l2 = [1] * (X_train.shape[1])\n",
    "lambda_vec2 = np.array(l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 2\n",
    "# train and predict \n",
    "logic2 = mylogistic_l2(reg_vec = lambda_vec2, max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "logic2.fit(X_train, Y_train)\n",
    "ypred2 = logic2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous-valued: \n",
      "[[0.25829765]\n",
      " [0.35286355]\n",
      " [2.33421989]\n",
      " [0.76093037]\n",
      " [0.33328473]\n",
      " [0.07921358]]\n",
      "constant term: \n",
      "[-0.67642979]\n",
      "binary-valued: \n",
      "[[-0.41906501]\n",
      " [-0.20451829]\n",
      " [-0.96293739]\n",
      " [-1.33000528]\n",
      " [-0.32887968]\n",
      " [ 0.90975624]\n",
      " [-0.82700343]\n",
      " [-0.08741964]\n",
      " [-0.4336111 ]\n",
      " [-0.70534448]\n",
      " [-0.28227076]\n",
      " [-1.59439589]\n",
      " [-0.74125352]\n",
      " [-0.01306693]\n",
      " [ 0.05205653]\n",
      " [ 0.78777243]\n",
      " [-0.99240259]\n",
      " [-0.69494818]\n",
      " [-0.27531241]\n",
      " [-0.82656048]\n",
      " [-1.65298179]\n",
      " [ 0.50035667]\n",
      " [ 0.5744047 ]\n",
      " [ 0.27914971]\n",
      " [ 0.64286175]\n",
      " [-0.10294563]\n",
      " [-0.05522086]\n",
      " [-0.25465123]\n",
      " [-0.20782379]\n",
      " [ 0.59348693]\n",
      " [ 0.40713026]\n",
      " [-0.02200255]\n",
      " [-0.00265095]\n",
      " [-0.56924112]\n",
      " [-0.27740542]\n",
      " [-0.24561796]\n",
      " [-0.10973204]\n",
      " [-0.1785307 ]\n",
      " [-0.18530458]\n",
      " [-1.1801582 ]\n",
      " [ 0.09228902]\n",
      " [-0.14021619]\n",
      " [ 0.95308764]\n",
      " [ 0.43076916]\n",
      " [-0.52328048]\n",
      " [-1.29561268]\n",
      " [ 0.45661075]\n",
      " [-0.92159731]\n",
      " [-0.08387461]\n",
      " [-0.377851  ]\n",
      " [ 0.40295961]\n",
      " [ 0.56788744]\n",
      " [ 0.5513525 ]\n",
      " [-0.646118  ]\n",
      " [-0.08193625]\n",
      " [ 0.06989464]\n",
      " [-0.15796955]\n",
      " [-0.02724891]\n",
      " [ 0.01354307]\n",
      " [-0.31896669]\n",
      " [ 0.12772484]\n",
      " [ 0.4727378 ]\n",
      " [ 0.8610213 ]\n",
      " [ 0.12126426]\n",
      " [ 0.31527274]\n",
      " [-0.33233611]\n",
      " [-0.38869331]\n",
      " [-0.38430904]\n",
      " [-0.67919585]\n",
      " [-0.42890424]\n",
      " [ 0.417121  ]\n",
      " [ 0.10920407]\n",
      " [ 0.11723865]\n",
      " [-0.14731267]\n",
      " [-0.07426403]\n",
      " [-0.96113575]\n",
      " [-0.05557072]\n",
      " [-0.31865535]\n",
      " [-0.16974509]\n",
      " [ 0.31952357]\n",
      " [-0.80987719]\n",
      " [ 0.55779359]\n",
      " [ 0.34408602]\n",
      " [-0.34313169]\n",
      " [-0.15401317]\n",
      " [ 0.02252656]\n",
      " [-0.64130567]\n",
      " [-0.46470984]\n",
      " [-1.09910162]\n",
      " [-0.8664389 ]\n",
      " [ 1.32356592]\n",
      " [ 0.99914099]\n",
      " [-0.81846028]\n",
      " [-1.35692458]\n",
      " [-0.94010276]]\n"
     ]
    }
   ],
   "source": [
    "# show the learned w\n",
    "print(f'continuous-valued: \\n{logic2.regre_coef[:6]}')\n",
    "print(f'constant term: \\n{logic2.regre_coef[-1]}')\n",
    "print(f'binary-valued: \\n{logic2.regre_coef[6:-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.847808764940239\n"
     ]
    }
   ],
   "source": [
    "# count accuracy\n",
    "tp, tn = 0, 0\n",
    "\n",
    "for i in range(len(ypred2)):\n",
    "    if ypred2[i] >= 0.5 and Y_test[i] == 1:\n",
    "        tp += 1\n",
    "    elif ypred2[i] < 0.5 and Y_test[i] == 0:\n",
    "        tn += 1\n",
    "\n",
    "print(f'accuracy: {(tp + tn) / len(ypred2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Case3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [],
   "source": [
    "l3 = [0.5] * (X_train.shape[1])\n",
    "\n",
    "for i in range(6):\n",
    "    l3[i] = 1\n",
    "\n",
    "lambda_vec3 = np.array(l3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case 3\n",
    "# train and predict \n",
    "logic3 = mylogistic_l2(reg_vec = lambda_vec3, max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "logic3.fit(X_train, Y_train)\n",
    "ypred3 = logic3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continuous-valued: \n",
      "[[0.25849111]\n",
      " [0.35322394]\n",
      " [2.33598766]\n",
      " [0.80720414]\n",
      " [0.33410071]\n",
      " [0.07936585]]\n",
      "constant term: \n",
      "[-0.74636493]\n",
      "binary-valued: \n",
      "[[-0.49370728]\n",
      " [-0.19295337]\n",
      " [-1.0050973 ]\n",
      " [-1.34229158]\n",
      " [-0.31468835]\n",
      " [ 0.84363046]\n",
      " [-0.87808667]\n",
      " [-0.09614551]\n",
      " [-0.46490749]\n",
      " [-0.75188895]\n",
      " [-0.31407879]\n",
      " [-1.68121687]\n",
      " [-0.82389055]\n",
      " [ 0.05603865]\n",
      " [ 0.12039192]\n",
      " [ 0.85796829]\n",
      " [-0.93135847]\n",
      " [-0.63212227]\n",
      " [-0.20669766]\n",
      " [-0.76283362]\n",
      " [-2.11758619]\n",
      " [ 0.57041488]\n",
      " [ 0.64714161]\n",
      " [ 0.34852797]\n",
      " [ 0.71540949]\n",
      " [-0.03458635]\n",
      " [ 0.04509671]\n",
      " [-0.17291196]\n",
      " [-0.14684918]\n",
      " [ 0.80728452]\n",
      " [ 0.57899054]\n",
      " [ 0.11482209]\n",
      " [ 0.11852947]\n",
      " [-0.58010858]\n",
      " [-0.267173  ]\n",
      " [-0.27145853]\n",
      " [-0.18790836]\n",
      " [-0.13079654]\n",
      " [-0.22878516]\n",
      " [-2.10646627]\n",
      " [ 0.03377443]\n",
      " [-0.11114761]\n",
      " [ 1.12582835]\n",
      " [ 0.47939214]\n",
      " [-0.54372999]\n",
      " [-1.51873069]\n",
      " [ 0.51104375]\n",
      " [-1.12042128]\n",
      " [-0.07188977]\n",
      " [-0.38391316]\n",
      " [ 0.45411871]\n",
      " [ 0.6645264 ]\n",
      " [ 0.6026661 ]\n",
      " [-0.70054806]\n",
      " [-0.06921079]\n",
      " [ 0.11223596]\n",
      " [-0.25809655]\n",
      " [-0.0218094 ]\n",
      " [ 0.0438973 ]\n",
      " [-0.31740654]\n",
      " [ 0.16912286]\n",
      " [ 0.58133396]\n",
      " [ 0.93472721]\n",
      " [ 0.16432701]\n",
      " [ 0.35544573]\n",
      " [-0.40736799]\n",
      " [-0.36621646]\n",
      " [-0.43956779]\n",
      " [-0.99743707]\n",
      " [-0.50568081]\n",
      " [ 0.44178914]\n",
      " [ 0.15102727]\n",
      " [ 0.16341912]\n",
      " [-0.12281147]\n",
      " [-0.07119001]\n",
      " [-1.0257096 ]\n",
      " [-0.04941245]\n",
      " [-0.38276283]\n",
      " [-0.19463369]\n",
      " [ 0.35428065]\n",
      " [-0.90694455]\n",
      " [ 0.69084484]\n",
      " [ 0.3842178 ]\n",
      " [-0.30548917]\n",
      " [-0.11471579]\n",
      " [ 0.06167814]\n",
      " [-0.60282267]\n",
      " [-0.42775412]\n",
      " [-1.5002216 ]\n",
      " [-0.93320019]\n",
      " [ 1.49153387]\n",
      " [ 1.01871184]\n",
      " [-0.90056393]\n",
      " [-1.42141828]\n",
      " [-1.01380578]]\n"
     ]
    }
   ],
   "source": [
    "# show the learned w\n",
    "print(f'continuous-valued: \\n{logic3.regre_coef[:6]}')\n",
    "print(f'constant term: \\n{logic3.regre_coef[-1]}')\n",
    "print(f'binary-valued: \\n{logic3.regre_coef[6:-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.847675962815405\n"
     ]
    }
   ],
   "source": [
    "# count accuracy\n",
    "tp, tn = 0, 0\n",
    "\n",
    "for i in range(len(ypred3)):\n",
    "    if ypred3[i] >= 0.5 and Y_test[i] == 1:\n",
    "        tp += 1\n",
    "    elif ypred3[i] < 0.5 and Y_test[i] == 0:\n",
    "        tn += 1\n",
    "\n",
    "print(f'accuracy: {(tp + tn) / len(ypred3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#concate x_train and y_train\n",
    "train_data = np.column_stack((X_train, Y_train))\n",
    "\n",
    "# split training data into 2 sets\n",
    "subtrain_data, tune_data = train_test_split(train_data, random_state=777, train_size=0.9) \n",
    "X_tune = tune_data[:,:-1]\n",
    "Y_tune = tune_data[:,-1]\n",
    "X_subtrain = subtrain_data[:,:-1]\n",
    "Y_subtrain = subtrain_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8.433418917367074,\n",
       " 6.275733578049139,\n",
       " 2.654150200664584,\n",
       " 9.606426218490203,\n",
       " 6.268778720491513,\n",
       " 7.0615606107540145,\n",
       " 5.89984612700335,\n",
       " 4.880616863791111,\n",
       " 0.8913257995678492,\n",
       " 3.161205375980107]"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "grids = []\n",
    "\n",
    "for grid in range(10):\n",
    "    grids.append(random.uniform(0.01, 10)) # 10 grids in [0.01, 10]\n",
    "grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_1 = a_2\n",
    "\n",
    "accuracy_list = []\n",
    "for t in range(10):\n",
    "    grid = grids[t]\n",
    "\n",
    "    lst = [grid] * (X_tune.shape[1]) # a_1 = a_2 = grid\n",
    "    lambda_vector = np.array(lst)\n",
    "\n",
    "    logicT = mylogistic_l2(reg_vec = lambda_vector, max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "    logicT.fit(X_tune, Y_tune)\n",
    "    ypredT = logicT.predict(X_test)\n",
    "\n",
    "    \n",
    "    tp, tn = 0, 0\n",
    "    for i in range(len(ypredT)):\n",
    "        if ypredT[i] >= 0.5 and Y_test[i] == 1:\n",
    "            tp += 1\n",
    "        elif ypredT[i] < 0.5 and Y_test[i] == 0:\n",
    "            tn += 1\n",
    "\n",
    "    accu = (tp + tn) / len(ypredT)\n",
    "    accuracy_list.append(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_1* = a_2* = 4.880616863791111\n"
     ]
    }
   ],
   "source": [
    "max_accu = max(accuracy_list)\n",
    "accu_pos = 0\n",
    "for j in range(10):\n",
    "    if accuracy_list[j] == max_accu:\n",
    "        accu_pos = j\n",
    "        break\n",
    "\n",
    "print(f'a_1* = a_2* = {grids[accu_pos]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix a1, find new a_2*\n",
    "a2accu_list = []\n",
    "a1 = 4.880616863791111\n",
    "\n",
    "a2_grids = []\n",
    "for g in range(10):\n",
    "    a2_grids.append(random.uniform(0.01, 10)) # 10 grids in [0.01, 10]\n",
    "\n",
    "for t in range(10):\n",
    "    grid = a2_grids[t]\n",
    "\n",
    "    lst = [grid] * (X_tune.shape[1])\n",
    "    for i in range(6):\n",
    "        lst[i] = a1\n",
    "    lambda_vector = np.array(lst)\n",
    "\n",
    "    logicT = mylogistic_l2(reg_vec = lambda_vector, max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "    logicT.fit(X_tune, Y_tune)\n",
    "    ypredT = logicT.predict(X_test)\n",
    "\n",
    "    \n",
    "    tp, tn = 0, 0\n",
    "    for i in range(len(ypredT)):\n",
    "        if ypredT[i] >= 0.5 and Y_test[i] == 1:\n",
    "            tp += 1\n",
    "        elif ypredT[i] < 0.5 and Y_test[i] == 0:\n",
    "            tn += 1\n",
    "\n",
    "    accu = (tp + tn) / len(ypredT)\n",
    "    a2accu_list.append(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new a_2* = 5.107690838241165\n"
     ]
    }
   ],
   "source": [
    "max_accu = max(a2accu_list)\n",
    "accu_pos = 0\n",
    "for j in range(10):\n",
    "    if a2accu_list[j] == max_accu:\n",
    "        accu_pos = j\n",
    "        break\n",
    "\n",
    "print(f'new a_2* = {a2_grids[accu_pos]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix a2, find new a_1*\n",
    "a1accu_list = []\n",
    "a2 = 5.107690838241165\n",
    "\n",
    "a1_grids = []\n",
    "for g in range(10):\n",
    "    a1_grids.append(random.uniform(0.01, 10)) # 10 grids in [0.01, 10]\n",
    "\n",
    "for t in range(10):\n",
    "    grid = a1_grids[t]\n",
    "\n",
    "    lst = [a2] * (X_tune.shape[1])\n",
    "    for i in range(6):\n",
    "        lst[i] = grid\n",
    "    lambda_vector = np.array(lst)\n",
    "\n",
    "    logicT = mylogistic_l2(reg_vec = lambda_vector, max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "    logicT.fit(X_tune, Y_tune)\n",
    "    ypredT = logicT.predict(X_test)\n",
    "\n",
    "    \n",
    "    tp, tn = 0, 0\n",
    "    for i in range(len(ypredT)):\n",
    "        if ypredT[i] >= 0.5 and Y_test[i] == 1:\n",
    "            tp += 1\n",
    "        elif ypredT[i] < 0.5 and Y_test[i] == 0:\n",
    "            tn += 1\n",
    "\n",
    "    accu = (tp + tn) / len(ypredT)\n",
    "    a1accu_list.append(accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new a_1* = 3.1123278599570012\n"
     ]
    }
   ],
   "source": [
    "max_accu = max(a1accu_list)\n",
    "accu_pos = 0\n",
    "for j in range(10):\n",
    "    if a1accu_list[j] == max_accu:\n",
    "        accu_pos = j\n",
    "        break\n",
    "\n",
    "print(f'new a_1* = {a1_grids[accu_pos]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model using the selected hyper-parameters\n",
    "l4 = [5.107690838241165] * (X_train.shape[1]) # a_2*\n",
    "for i in range(6):\n",
    "    l4[i] = 3.1123278599570012 # a_1*\n",
    "\n",
    "lambda_vec4 = np.array(l4)\n",
    "\n",
    "logic4 = mylogistic_l2(reg_vec = lambda_vec4, max_iter = 1000, tol = 1e-5, add_intercept = False)\n",
    "logic4.fit(X_train, Y_train)\n",
    "ypred4 = logic4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.848539176626826\n"
     ]
    }
   ],
   "source": [
    "# count accuracy\n",
    "tp, tn = 0, 0\n",
    "\n",
    "for i in range(len(ypred4)):\n",
    "    if ypred4[i] >= 0.5 and Y_test[i] == 1:\n",
    "        tp += 1\n",
    "    elif ypred4[i] < 0.5 and Y_test[i] == 0:\n",
    "        tn += 1\n",
    "\n",
    "print(f'accuracy: {(tp + tn) / len(ypred4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations\n",
    "\n",
    "- Accuracy  \n",
    "case1: 0.847875166002656  \n",
    "case2: 0.847808764940239  \n",
    "case3: 0.847675962815405  \n",
    "Use the selected hyper-parameters: 0.848539176626826\n",
    "\n",
    "After searching for the best hyperparameters, accuracy of model using the selected hyper-parameters are both higher than previous case1, case2 and case3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5cfa4b7dcd7864583d72e5eda12e513f8c53c522d90114d3c5fb0ab3f428a316"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
